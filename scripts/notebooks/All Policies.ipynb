{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import secrets\n",
    "import json\n",
    "import sys\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patient.simulator import run_multi_seed\n",
    "from patient.baseline_policies import *\n",
    "from patient.lp_policies import *\n",
    "from patient.group_based_policies import *\n",
    "from patient.ordering_policies import *\n",
    "from patient.provider_policies import *\n",
    "from patient.utils import get_save_path, delete_duplicate_results, restrict_resources, one_shot_policy, MyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 45\n",
    "    num_patients = 25\n",
    "    num_providers = 25\n",
    "    provider_capacity = 1\n",
    "    top_choice_prob = 0.9\n",
    "    true_top_choice_prob = 0.9\n",
    "    choice_model = \"uniform_choice\"\n",
    "    exit_option = 0.5\n",
    "    utility_function = \"normal\"\n",
    "    out_folder = \"policy_comparison\"\n",
    "    num_repetitions = 1\n",
    "    num_trials = 100\n",
    "    context_dim = 5\n",
    "    max_menu_size = 25\n",
    "    previous_patients_per_provider = 10\n",
    "    order=\"custom\"\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', help='Random Seed', type=int, default=42)\n",
    "    parser.add_argument('--n_patients',         '-N', help='Number of patients', type=int, default=100)\n",
    "    parser.add_argument('--n_providers',        help='Number of providers', type=int, default=100)\n",
    "    parser.add_argument('--n_trials',          help='Number of trials ', type=int, default=2)\n",
    "    parser.add_argument('--top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--true_top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--context_dim',          help='Context dim for patients and providers', type=int, default=5)\n",
    "    parser.add_argument('--max_menu_size',          help='Context dim for patients and providers', type=int, default=50)\n",
    "    parser.add_argument('--num_repetitions',          help='Context dim for patients and providers', type=int, default=1)\n",
    "    parser.add_argument('--previous_patients_per_provider',          help='Context dim for patients and providers', type=int, default=10)\n",
    "    parser.add_argument('--provider_capacity', help='Provider Capacity', type=int, default=5)\n",
    "    parser.add_argument('--choice_model', help='Which choice model for patients', type=str, default='uniform_choice')\n",
    "    parser.add_argument('--exit_option', help='What is the value of the exit option', type=float, default=0.5)\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='policy_comparison')\n",
    "    parser.add_argument('--utility_function', help='Which folder to write results to', type=str, default='uniform')\n",
    "    parser.add_argument('--order', help='Which folder to write results to', type=str, default='random')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    seed = args.seed\n",
    "    num_patients = args.n_patients\n",
    "    num_providers = args.n_providers \n",
    "    provider_capacity = args.provider_capacity\n",
    "    top_choice_prob = args.top_choice_prob\n",
    "    choice_model = args.choice_model\n",
    "    exit_option = args.exit_option\n",
    "    out_folder = args.out_folder\n",
    "    num_trials = args.n_trials \n",
    "    context_dim = args.context_dim \n",
    "    num_repetitions = args.num_repetitions\n",
    "    true_top_choice_prob = args.true_top_choice_prob\n",
    "    max_menu_size = args.max_menu_size\n",
    "    utility_function = args.utility_function\n",
    "    order = args.order\n",
    "    previous_patients_per_provider = args.previous_patients_per_provider\n",
    "\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'num_patients'    : num_patients,\n",
    "        'num_providers': num_providers, \n",
    "        'provider_capacity'    : provider_capacity,\n",
    "        'top_choice_prob': top_choice_prob, \n",
    "        'choice_model': choice_model,\n",
    "        'exit_option': exit_option,\n",
    "        'num_trials': num_trials,\n",
    "        'context_dim': context_dim, \n",
    "        'true_top_choice_prob': true_top_choice_prob, \n",
    "        'num_repetitions': num_repetitions, \n",
    "        'max_menu_size': max_menu_size, \n",
    "        'utility_function': utility_function, \n",
    "        'order': order, \n",
    "        'previous_patients_per_provider': previous_patients_per_provider} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [43,44,45]\n",
    "restrict_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random policy\n",
      "Took 0.13887715339660645 time\n",
      "Took 0.1494443416595459 time\n",
      "Took 0.13875770568847656 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8881333333333333, 0.5645886688751071)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = random_policy\n",
    "name = \"random\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_repetitions*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_repetitions*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy_basic policy\n",
      "Took 0.13116049766540527 time\n",
      "Took 0.13119721412658691 time\n",
      "Took 0.1313169002532959 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20158441545701056, 0.7971882107537853, 0.06604648734464585)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = all_ones_policy\n",
    "name = \"greedy_basic\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.mean(results['{}_minimums_all'.format(name)]),np.mean(results['{}_gaps_all'.format(name)]),np.mean(results['{}_variance_all'.format(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy policy\n",
      "Took 0.13083291053771973 time\n",
      "Took 0.13124680519104004 time\n",
      "Took 0.13071727752685547 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8992, 0.5992348440924347)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = greedy_policy\n",
    "name = \"greedy\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2**(num_patients*num_providers)*2**(num_patients)*math.factorial(num_patients) < 100000:\n",
    "    policy = one_shot_policy\n",
    "    per_epoch_function = optimal_policy\n",
    "    name = \"optimal\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_order policy\n",
      "Took 0.017654895782470703 time\n",
      "0.758 0.5405452364134852\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = optimal_order_policy\n",
    "name = \"optimal_order\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp policy\n",
      "Took 0.1250309944152832 time\n",
      "Took 0.12516140937805176 time\n",
      "Took 0.12550830841064453 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8992, 0.6274295980840595, 7.497791691877962)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_policy\n",
    "name = \"lp\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_workload policy\n",
      "Took 0.5431537628173828 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 6.892960645691221, 6.892960645691221)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_workload_policy\n",
    "name = \"lp_workload\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_multiple_match policy\n",
      "Took 0.09562230110168457 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2536, 0.23916547111746667)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_multiple_match_policy\n",
    "name = \"lp_multiple_match\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice_model == 'threshold':\n",
    "    policy = one_shot_policy \n",
    "    per_epoch_function = lp_threshold\n",
    "    name = \"lp_threshold\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_more_patients policy\n",
      "Took 0.6590728759765625 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = lp_more_patients_policy\n",
    "name = \"lp_more_patients\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_fairness policy\n",
      "Took 0.5672309398651123 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.4479570155876951)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_fairness_policy\n",
    "name = \"lp_fairness\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based policy\n",
      "Took 0.715339183807373 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_policy\n",
    "name = \"group_based\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based_unidirectional policy\n",
      "Took 0.7381973266601562 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7504, 0.5187739882075151)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_unidirectional_policy\n",
    "name = \"group_based_unidirectional\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused policy\n",
      "B 3, Per provider [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3.], Per Patient [1. 4. 1. 3. 4. 4. 3. 4. 2. 5. 1. 1. 2. 5. 2. 2. 3. 2. 4. 4. 5. 5. 1. 4.\n",
      " 3.]\n",
      "Took 0.1559138298034668 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6824, 0.511133744634547)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_policy\n",
    "name = \"provider_focused\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_less_interference policy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seed_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_705884/2735123428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} policy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_multi_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper_epoch_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}_matches'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed_list' is not defined"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_less_interference_policy\n",
    "name = \"provider_focused_less_interference\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_linear_regularization_0.25 policy\n",
      "B 1, Per provider [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [2. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "Took 0.03953838348388672 time\n",
      "0.25 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_0.5 policy\n",
      "B 1, Per provider [1. 0. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [1. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/patient_provider/patient/provider_policies.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  real_value += upper/lower*prod\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0397343635559082 time\n",
      "0.5 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_1 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.031838178634643555 time\n",
      "1 0.0 0.0\n",
      "provider_focused_linear_regularization_2 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03140616416931152 time\n",
      "2 0.0 0.0\n",
      "provider_focused_linear_regularization_4 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03318023681640625 time\n",
      "4 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "for lamb in [0.25,0.5,1,2,4]:\n",
    "    per_epoch_function = provider_focused_linear_regularization_policy(lamb)\n",
    "    name = \"provider_focused_linear_regularization_{}\".format(lamb)\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = one_shot_policy \n",
    "# for lamb in [0,0.1,0.25,0.5]:#,1,2,4]:\n",
    "#     per_epoch_function = provider_focused_log_regularization_policy(lamb)\n",
    "#     name = \"provider_focused_log_regularization_{}\".format(lamb)\n",
    "#     print(\"{} policy\".format(name))\n",
    "\n",
    "#     rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "#     results['{}_matches'.format(name)] = rewards['matches']\n",
    "#     results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "#     results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "#     results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "#     results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "#     results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "#     results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "#     results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "#     results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "#     results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "#     print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent policy\n",
      "Took 0.14566659927368164 time\n",
      "0.2 0.09402573838226778\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = gradient_descent_policy\n",
    "name = \"gradient_descent\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent_2 policy\n",
      "Took 0.12857437133789062 time\n",
      "Took 0.12943243980407715 time\n",
      "Took 0.1285691261291504 time\n",
      "0.8992 0.6274295980840595\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = gradient_descent_policy_2\n",
    "name = \"gradient_descent_2\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP Policy [[0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "LP Policy [[0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "Chosen x tensor([[0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 0.]])\n",
      "tensor(0.4816) tensor(0.2630) tensor(0.4954)\n"
     ]
    }
   ],
   "source": [
    "if is_jupyter:\n",
    "    theta = [p.provider_rewards for p in simulator.patients]\n",
    "    theta = torch.Tensor(theta)\n",
    "    sorted_theta = torch.argsort(theta, dim=1)  # Sorting indices of `theta` row-wise\n",
    "    opt_tensor = torch.Tensor(lp_policy(simulator))\n",
    "    ones_tensor = torch.Tensor(np.ones(opt_tensor.shape))\n",
    "    x = torch.Tensor(gradient_descent_policy_2(simulator))\n",
    "    p = true_top_choice_prob\n",
    "    print(objective(opt_tensor*10000-10000/2,theta,p,sorted_theta,0), objective(ones_tensor*10000-10000/2,theta,p,sorted_theta,0), objective(x*10000-10000/2,theta,p,sorted_theta,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../../results/'+save_path,'w'),cls=MyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
