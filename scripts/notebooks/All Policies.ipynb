{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import secrets\n",
    "import json\n",
    "import sys\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr0/home/naveenr/projects/patient_provider')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patient.simulator import run_multi_seed\n",
    "from patient.baseline_policies import *\n",
    "from patient.lp_policies import *\n",
    "from patient.utils import get_save_path, delete_duplicate_results, restrict_resources, one_shot_policy, MyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 43\n",
    "    num_patients = 5\n",
    "    num_providers = 5\n",
    "    provider_capacity = 1\n",
    "    noise = 0\n",
    "    fairness_constraint = -1\n",
    "    num_trials = 10\n",
    "    utility_function = \"semi_synthetic_comorbidity\"\n",
    "    order=\"uniform\"\n",
    "    online_arrival = False  \n",
    "    new_provider = True \n",
    "    out_folder = \"policy_comparison\"\n",
    "    average_distance = 20.2\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', help='Random Seed', type=int, default=42)\n",
    "    parser.add_argument('--n_patients',         '-N', help='Number of patients', type=int, default=100)\n",
    "    parser.add_argument('--n_providers',        help='Number of providers', type=int, default=100)\n",
    "    parser.add_argument('--provider_capacity', help='Provider Capacity', type=int, default=1)\n",
    "    parser.add_argument('--noise', help='Noise in theta', type=float, default=0.1)\n",
    "    parser.add_argument('--average_distance', help='Maximum distance patients are willing to go', type=float, default=20.2)\n",
    "    parser.add_argument('--fairness_constraint', help='Maximum difference in average utility between groups', type=float, default=-1)\n",
    "    parser.add_argument('--num_trials', help='Number of trials', type=int, default=100)\n",
    "    parser.add_argument('--utility_function', help='Which folder to write results to', type=str, default='uniform')\n",
    "    parser.add_argument('--order', help='Which folder to write results to', type=str, default='uniform')\n",
    "    parser.add_argument(\"--online_arrival\",action=\"store_true\",help=\"Patients arrive one-by-one\")\n",
    "    parser.add_argument(\"--new_provider\",action=\"store_true\",help=\"Are we simulating a new provider matching\")\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='policy_comparison')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    seed = args.seed\n",
    "    num_patients = args.n_patients\n",
    "    num_providers = args.n_providers \n",
    "    num_trials = args.num_trials\n",
    "    noise = args.noise\n",
    "    average_distance = args.average_distance\n",
    "    fairness_constraint = args.fairness_constraint\n",
    "    provider_capacity = args.provider_capacity\n",
    "    utility_function = args.utility_function\n",
    "    order = args.order\n",
    "    online_arrival = args.online_arrival\n",
    "    new_provider = args.new_provider \n",
    "    out_folder = args.out_folder\n",
    "    \n",
    "assert not(online_arrival and new_provider)\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'num_patients'    : num_patients,\n",
    "        'num_providers': num_providers, \n",
    "        'provider_capacity'    : provider_capacity,\n",
    "        'utility_function': utility_function, \n",
    "        'order': order, \n",
    "        'num_trials': num_trials, \n",
    "        'noise': noise, \n",
    "        'average_distance': average_distance,\n",
    "        'online_arrival': online_arrival,\n",
    "        'new_provider': new_provider,\n",
    "        'fairness_constraint': fairness_constraint} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [seed]\n",
    "restrict_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random policy\n",
      "Matches 0.5, Utilities 0.49967781998878197\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = random_policy\n",
    "name = \"random\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "for key in rewards:\n",
    "    results['{}_{}'.format(name,key)] = rewards[key]\n",
    "print(\"Matches {}, Utilities {}\".format(np.mean(results['random_num_matches'])/num_patients,np.mean(results['random_patient_utilities'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy policy\n",
      "Matches 1.0, Utilities 0.7696011012838758\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = greedy_policy\n",
    "name = \"greedy\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "for key in rewards:\n",
    "    results['{}_{}'.format(name,key)] = rewards[key]\n",
    "print(\"Matches {}, Utilities {}\".format(np.mean(results['{}_num_matches'.format(name)])/num_patients,np.mean(results['{}_patient_utilities'.format(name)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omniscient_optimal policy\n",
      "Matches 1.0, Utilities 0.775\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "if fairness_constraint != -1:\n",
    "    per_epoch_function = get_fair_optimal_policy(fairness_constraint,seed)\n",
    "else:\n",
    "    per_epoch_function = optimal_policy\n",
    "name = \"omniscient_optimal\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function,use_real=True)\n",
    "\n",
    "for key in rewards:\n",
    "    results['{}_{}'.format(name,key)] = rewards[key]\n",
    "print(\"Matches {}, Utilities {}\".format(np.mean(results['{}_num_matches'.format(name)])/num_patients,np.mean(results['{}_patient_utilities'.format(name)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp policy\n",
      "Matches 1.0, Utilities 0.775\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_policy\n",
    "name = \"lp\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "for key in rewards:\n",
    "    results['{}_{}'.format(name,key)] = rewards[key]\n",
    "print(\"Matches {}, Utilities {}\".format(np.mean(results['{}_num_matches'.format(name)])/num_patients,np.mean(results['{}_patient_utilities'.format(name)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent policy\n",
      "Iter 0: Obj = 0.8668, Worst = 0.4508, AdvSteps = 10\n",
      "Iter 10: Obj = 0.9366, Worst = 0.5527, AdvSteps = 9\n",
      "Iter 20: Obj = 0.9819, Worst = 0.6241, AdvSteps = 8\n",
      "Iter 30: Obj = 1.0025, Worst = 0.6715, AdvSteps = 7\n",
      "Early stopping at iteration 40 (improvement: 0.0086)\n",
      "Iter 0: Obj = 1.1248, Worst = 0.6411, AdvSteps = 10\n",
      "Iter 10: Obj = 1.2263, Worst = 0.7487, AdvSteps = 9\n",
      "Iter 20: Obj = 1.2892, Worst = 0.8228, AdvSteps = 8\n",
      "Iter 30: Obj = 1.3171, Worst = 0.8602, AdvSteps = 7\n",
      "Iter 40: Obj = 1.3288, Worst = 0.8957, AdvSteps = 6\n",
      "Early stopping at iteration 50 (improvement: 0.0054)\n",
      "Iter 0: Obj = 1.1237, Worst = 0.6401, AdvSteps = 10\n",
      "Iter 10: Obj = 1.2254, Worst = 0.7478, AdvSteps = 9\n",
      "Iter 20: Obj = 1.2887, Worst = 0.8224, AdvSteps = 8\n",
      "Iter 30: Obj = 1.3169, Worst = 0.8601, AdvSteps = 7\n",
      "Iter 40: Obj = 1.3287, Worst = 0.8956, AdvSteps = 6\n",
      "Early stopping at iteration 50 (improvement: 0.0055)\n",
      "Iter 0: Obj = 1.1920, Worst = 0.7110, AdvSteps = 10\n",
      "Iter 10: Obj = 1.2904, Worst = 0.8108, AdvSteps = 9\n",
      "Iter 20: Obj = 1.3517, Worst = 0.8779, AdvSteps = 8\n",
      "Iter 30: Obj = 1.3789, Worst = 0.9142, AdvSteps = 7\n",
      "Iter 40: Obj = 1.3903, Worst = 0.9509, AdvSteps = 6\n",
      "Early stopping at iteration 50 (improvement: 0.0053)\n",
      "Iter 0: Obj = 1.3668, Worst = 0.8900, AdvSteps = 10\n",
      "Iter 10: Obj = 1.4600, Worst = 0.9840, AdvSteps = 9\n",
      "Iter 20: Obj = 1.5165, Worst = 1.0463, AdvSteps = 8\n",
      "Iter 30: Obj = 1.5413, Worst = 1.0775, AdvSteps = 7\n",
      "Iter 40: Obj = 1.5517, Worst = 1.1091, AdvSteps = 6\n",
      "Early stopping at iteration 50 (improvement: 0.0048)\n",
      "Iter 0: Obj = 1.3659, Worst = 0.8893, AdvSteps = 10\n",
      "Iter 10: Obj = 1.4593, Worst = 0.9833, AdvSteps = 9\n",
      "Iter 20: Obj = 1.5161, Worst = 1.0460, AdvSteps = 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m name = \u001b[33m\"\u001b[39m\u001b[33mgradient_descent\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m policy\u001b[39m\u001b[33m\"\u001b[39m.format(name))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m rewards, simulator = \u001b[43mrun_multi_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mparameters\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mper_epoch_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m rewards:\n\u001b[32m      9\u001b[39m     results[\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(name,key)] = rewards[key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/patient_provider/patient/simulator.py:330\u001b[39m, in \u001b[36mrun_multi_seed\u001b[39m\u001b[34m(seed_list, policy, parameters, per_epoch_function, use_real)\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seed_list:\n\u001b[32m    329\u001b[39m     simulator = Simulator(num_patients,num_providers,provider_capacity,num_trials,utility_function,order,noise,online_arrival,new_provider,average_distance,seed)\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     patient_results, patient_orders, new_providers, assortment = \u001b[43mrun_heterogenous_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43mper_epoch_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mper_epoch_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_real\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_real\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m new_provider:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdouble_tuple\u001b[39m(t):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/patient_provider/patient/simulator.py:261\u001b[39m, in \u001b[36mrun_heterogenous_policy\u001b[39m\u001b[34m(env, policy, seed, num_trials, per_epoch_function, use_real)\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    258\u001b[39m     parameters = {\u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m: np.clip(new_weights + np.random.normal(\u001b[32m0\u001b[39m, noise, new_weights.shape),\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m),\n\u001b[32m    259\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mcapacities\u001b[39m\u001b[33m'\u001b[39m: new_capacities, \u001b[33m'\u001b[39m\u001b[33monline_arrival\u001b[39m\u001b[33m'\u001b[39m: env.online_arrival}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m single_provider_results = \u001b[43mper_epoch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m env.reset_patient_order(trial_num+num_trials)\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(env.num_patients):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/patient_provider/patient/lp_policies.py:20\u001b[39m, in \u001b[36mgradient_policy\u001b[39m\u001b[34m(parameters, error_threshold)\u001b[39m\n\u001b[32m     18\u001b[39m weights = parameters[\u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     19\u001b[39m capacities = parameters[\u001b[33m'\u001b[39m\u001b[33mcapacities\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m N,M = weights.shape \n\u001b[32m     21\u001b[39m M -= \u001b[32m1\u001b[39m \n\u001b[32m     22\u001b[39m lp_solution = solve_linear_program(weights,capacities)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:23\u001b[39m, in \u001b[36moptimize\u001b[39m\u001b[34m(self, n_iterations, lr, initial_adv_steps, min_adv_steps, adv_lr, temperature_schedule, verbose, eval_frequency, early_stop_threshold)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/patient_provider/patient/lp_policies.py:23\u001b[39m, in \u001b[36mfind_worst_case_perturbation\u001b[39m\u001b[34m(self, X, permutations, n_adv_steps, adv_lr)\u001b[39m\n\u001b[32m     21\u001b[39m M -= \u001b[32m1\u001b[39m \n\u001b[32m     22\u001b[39m lp_solution = solve_linear_program(weights,capacities)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m assortment = np.zeros((N,M))\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (i,j) \u001b[38;5;129;01min\u001b[39;00m lp_solution:\n\u001b[32m     26\u001b[39m     assortment[i,j] = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/patient_provider/patient/lp_policies.py:84\u001b[39m, in \u001b[36mAssortmentOptimizer.compute_objective\u001b[39m\u001b[34m(self, X, weights, permutations)\u001b[39m\n\u001b[32m     81\u001b[39m total_utility = \u001b[32m0.0\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m perm \u001b[38;5;129;01min\u001b[39;00m permutations:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     utility = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_single_permutation_differentiable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     total_utility += utility\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_utility / \u001b[38;5;28mself\u001b[39m.n_permutations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/patient_provider/patient/lp_policies.py:14\u001b[39m, in \u001b[36m_compute_single_permutation_differentiable\u001b[39m\u001b[34m(self, X, weights, permutation)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlp_policy\u001b[39m(parameters):\n\u001b[32m     12\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Policy which selects according to the LP, in an offline fashion\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[33;03m    Arguments:\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m        simulator: Simulator for patient-provider matching\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    Returns: List of providers on the menu\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m     weights = parameters[\u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     19\u001b[39m     capacities = parameters[\u001b[33m'\u001b[39m\u001b[33mcapacities\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = gradient_policy\n",
    "name = \"gradient_descent\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "for key in rewards:\n",
    "    results['{}_{}'.format(name,key)] = rewards[key]\n",
    "print(\"Matches {}, Utilities {}\".format(np.mean(results['{}_num_matches'.format(name)])/num_patients,np.mean(results['{}_patient_utilities'.format(name)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../../results/'+save_path,'w'),cls=MyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
