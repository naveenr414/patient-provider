{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import secrets\n",
    "import json\n",
    "import sys\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patient.simulator import run_multi_seed\n",
    "from patient.baseline_policies import *\n",
    "from patient.lp_policies import *\n",
    "from patient.group_based_policies import *\n",
    "from patient.ordering_policies import *\n",
    "from patient.provider_policies import *\n",
    "from patient.utils import get_save_path, delete_duplicate_results, restrict_resources, one_shot_policy, MyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 43\n",
    "    num_patients = 5\n",
    "    num_providers = 5\n",
    "    provider_capacity = 1\n",
    "    top_choice_prob = 0.5\n",
    "    true_top_choice_prob = 0.5\n",
    "    choice_model = \"uniform_choice\"\n",
    "    exit_option = 0.5\n",
    "    utility_function = \"normal\"\n",
    "    out_folder = \"policy_comparison\"\n",
    "    num_repetitions = 1\n",
    "    num_trials = 10000\n",
    "    context_dim = 5\n",
    "    max_menu_size = 25\n",
    "    previous_patients_per_provider = 10\n",
    "    order=\"custom\"\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', help='Random Seed', type=int, default=42)\n",
    "    parser.add_argument('--n_patients',         '-N', help='Number of patients', type=int, default=100)\n",
    "    parser.add_argument('--n_providers',        help='Number of providers', type=int, default=100)\n",
    "    parser.add_argument('--n_trials',          help='Number of trials ', type=int, default=2)\n",
    "    parser.add_argument('--top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--true_top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--context_dim',          help='Context dim for patients and providers', type=int, default=5)\n",
    "    parser.add_argument('--max_menu_size',          help='Context dim for patients and providers', type=int, default=50)\n",
    "    parser.add_argument('--num_repetitions',          help='Context dim for patients and providers', type=int, default=1)\n",
    "    parser.add_argument('--previous_patients_per_provider',          help='Context dim for patients and providers', type=int, default=10)\n",
    "    parser.add_argument('--provider_capacity', help='Provider Capacity', type=int, default=5)\n",
    "    parser.add_argument('--choice_model', help='Which choice model for patients', type=str, default='uniform_choice')\n",
    "    parser.add_argument('--exit_option', help='What is the value of the exit option', type=float, default=0.5)\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='policy_comparison')\n",
    "    parser.add_argument('--utility_function', help='Which folder to write results to', type=str, default='uniform')\n",
    "    parser.add_argument('--order', help='Which folder to write results to', type=str, default='random')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    seed = args.seed\n",
    "    num_patients = args.n_patients\n",
    "    num_providers = args.n_providers \n",
    "    provider_capacity = args.provider_capacity\n",
    "    top_choice_prob = args.top_choice_prob\n",
    "    choice_model = args.choice_model\n",
    "    exit_option = args.exit_option\n",
    "    out_folder = args.out_folder\n",
    "    num_trials = args.n_trials \n",
    "    context_dim = args.context_dim \n",
    "    num_repetitions = args.num_repetitions\n",
    "    true_top_choice_prob = args.true_top_choice_prob\n",
    "    max_menu_size = args.max_menu_size\n",
    "    utility_function = args.utility_function\n",
    "    order = args.order\n",
    "    previous_patients_per_provider = args.previous_patients_per_provider\n",
    "\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'num_patients'    : num_patients,\n",
    "        'num_providers': num_providers, \n",
    "        'provider_capacity'    : provider_capacity,\n",
    "        'top_choice_prob': top_choice_prob, \n",
    "        'choice_model': choice_model,\n",
    "        'exit_option': exit_option,\n",
    "        'num_trials': num_trials,\n",
    "        'context_dim': context_dim, \n",
    "        'true_top_choice_prob': true_top_choice_prob, \n",
    "        'num_repetitions': num_repetitions, \n",
    "        'max_menu_size': max_menu_size, \n",
    "        'utility_function': utility_function, \n",
    "        'order': order, \n",
    "        'previous_patients_per_provider': previous_patients_per_provider} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [seed]\n",
    "restrict_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random policy\n",
      "Available providers [[[0.2, 0.2, 0.2, 0.2, 0.2], [0.19021255561047948, 0.1598615916955017, 0.16480474542758278, 0.1964409293129016, 0.19031141868512108], [0.17787524366471735, 0.12602339181286548, 0.12631578947368421, 0.19220272904483432, 0.17855750487329433], [0.1641287685232499, 0.10495656617271334, 0.1022994379151763, 0.18456821665815024, 0.1600408788962698], [0.14603491271820448, 0.07940149625935161, 0.08029925187032419, 0.1762593516209476, 0.14204488778054863]], [[0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998], [0.1917440660474716, 0.16171310629514962, 0.16253869969040247, 0.19772961816305468, 0.18988648090815272], [0.17785787847579815, 0.1270854788877446, 0.1320288362512873, 0.19145211122554068, 0.17703398558187436], [0.16121031746031744, 0.1, 0.10297619047619047, 0.18680555555555553, 0.1603174603174603], [0.1447241045498548, 0.07628267182962246, 0.0824782187802517, 0.17686350435624396, 0.14278799612778317]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.19187314172447967, 0.1649157581764123, 0.15688800792864221, 0.19762140733399405, 0.188404360753221], [0.18205513784461153, 0.13774436090225564, 0.12190476190476189, 0.19218045112781953, 0.17453634085213032], [0.1652, 0.1103, 0.0951, 0.1874, 0.1557], [0.15128458498023714, 0.09219367588932806, 0.07302371541501976, 0.17470355731225296, 0.13616600790513833]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.19162148841793988, 0.16343026121241994, 0.16096599310004928, 0.19625431246919667, 0.1901429275505175], [0.18181818181818182, 0.13114754098360654, 0.12687531048186787, 0.19324391455538997, 0.1747640337804272], [0.16782396088019558, 0.10435207823960879, 0.10014669926650366, 0.1846454767726161, 0.15530562347188265], [0.14897750511247446, 0.0778118609406953, 0.08006134969325154, 0.17719836400817995, 0.13793456032719836]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.19116465863453813, 0.16927710843373495, 0.1575301204819277, 0.1968875502008032, 0.19106425702811242], [0.17867867867867868, 0.13633633633633632, 0.12372372372372373, 0.1915915915915916, 0.17787787787787787], [0.1615539858728557, 0.1101917255297679, 0.09283551967709384, 0.1846619576185671, 0.163773965691221], [0.14171369933299127, 0.08927655207798871, 0.07018984094407388, 0.17588506926629038, 0.14592098512057466]]]\n",
      "Top [[0.0534, 0.2637, 0.5066, 0.0147, 0.1616], [0.0543, 0.2577, 0.5093, 0.0162, 0.1625], [0.1654, 0.5247, 0.2472, 0.0172, 0.0455], [0.1693, 0.2644, 0.5069, 0.0138, 0.0456], [0.0516, 0.5314, 0.2439, 0.0165, 0.1566]]\n",
      "Selected [[0.0542, 0.1079, 0.1666, 0.0357, 0.0935], [0.0569, 0.1042, 0.1692, 0.0346, 0.0941], [0.0979, 0.179, 0.1026, 0.037, 0.0514], [0.1034, 0.1111, 0.1605, 0.0394, 0.0532], [0.0514, 0.1775, 0.0996, 0.0331, 0.1009]]\n",
      "Prob [0.3638 0.6797 0.6985 0.1798 0.3931]\n",
      "Took 2.2542483806610107 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46298, 0.3382126237895144)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = random_policy\n",
    "name = \"random\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_repetitions*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_repetitions*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy_basic policy\n",
      "Available providers [[[0.2, 0.2, 0.2, 0.2, 0.2], [0.19999999999999998, 0.14977755808205634, 0.14908551655956498, 0.19999999999999998, 0.19999999999999998], [0.2, 0.09249512670565302, 0.10155945419103314, 0.2, 0.2], [0.1869187531936638, 0.06356668369954012, 0.06213592233009709, 0.2, 0.1884517118037813], [0.1616957605985037, 0.03940149625935162, 0.03551122194513716, 0.19999999999999998, 0.16349127182044887]], [[0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998], [0.19999999999999998, 0.14685242518059854, 0.15376676986584106, 0.19999999999999998, 0.19999999999999998], [0.2, 0.09835221421215243, 0.10010298661174047, 0.2, 0.2], [0.1875, 0.06071428571428571, 0.060119047619047614, 0.2, 0.18759920634920635], [0.162729912875121, 0.03591481122942885, 0.03727008712487899, 0.2, 0.16311713455953533]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.1734390485629336, 0.12348860257680871, 0.2, 0.2], [0.2, 0.12531328320802004, 0.07548872180451127, 0.2, 0.2], [0.1937, 0.0801, 0.0458, 0.2, 0.1817], [0.17391304347826086, 0.05039525691699605, 0.025197628458498024, 0.19999999999999998, 0.15079051383399208]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.14775751601774273, 0.15120749137506162, 0.2, 0.2], [0.2, 0.10034773969200199, 0.09975161450571288, 0.2, 0.2], [0.19422982885085574, 0.06141809290953545, 0.06376528117359412, 0.19999999999999998, 0.17955990220048898], [0.17443762781186095, 0.03680981595092025, 0.03680981595092025, 0.2, 0.1512269938650307]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.19999999999999998, 0.1752008032128514, 0.1282128514056225, 0.19999999999999998, 0.19999999999999998], [0.2, 0.127027027027027, 0.07497497497497498, 0.2, 0.2], [0.18668012108980828, 0.0798183652875883, 0.044803229061553984, 0.2, 0.18779011099899093], [0.16110826064648537, 0.05038481272447408, 0.025243714725500254, 0.19999999999999998, 0.16244227809132888]]]\n",
      "Top [[0.1242, 0.2727, 0.2738, 0.0422, 0.2871], [0.1271, 0.2662, 0.2808, 0.0463, 0.2796], [0.3023, 0.31, 0.235, 0.0429, 0.1098], [0.297, 0.2751, 0.2722, 0.0417, 0.114], [0.1193, 0.3194, 0.2417, 0.0457, 0.2739]]\n",
      "Selected [[0.0176, 0.0798, 0.2739, 0.0067, 0.1185], [0.0209, 0.0784, 0.2683, 0.006, 0.1228], [0.1271, 0.3174, 0.0429, 0.0071, 0.0096], [0.1318, 0.081, 0.2785, 0.007, 0.0081], [0.0196, 0.3181, 0.0417, 0.0055, 0.1163]]\n",
      "Prob [0.317  0.8747 0.9053 0.0323 0.3753]\n",
      "Took 2.0897648334503174 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6793038712663703, 0.2606865459047239, 0.022657664338438785)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = all_ones_policy\n",
    "name = \"greedy_basic\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.mean(results['{}_minimums_all'.format(name)]),np.mean(results['{}_gaps_all'.format(name)]),np.mean(results['{}_variance_all'.format(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8528, 0.3911, 0.3956, 1.0000, 0.8592],\n",
       "        [0.8449, 0.3877, 0.4019, 1.0000, 0.8472],\n",
       "        [0.8902, 0.4613, 0.3307, 1.0000, 0.8128],\n",
       "        [0.8984, 0.3926, 0.3966, 1.0000, 0.8108],\n",
       "        [0.8511, 0.4738, 0.3423, 1.0000, 0.8556]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[[0.1963, 0.1963, 0.1963, 0.1963, 0.1963], [0.2023, 0.1278, 0.1235, 0.2023, 0.2023], [0.2052, 0.0446, 0.0516, 0.2052, 0.2052], [0.1528, 0.017, 0.0175, 0.1957, 0.1576], [0.0962, 0.0054, 0.0067, 0.2005, 0.0978]], [[0.2038, 0.2038, 0.2038, 0.2038, 0.2038], [0.1938, 0.1169, 0.1244, 0.1938, 0.1938], [0.1942, 0.0482, 0.0512, 0.1942, 0.1942], [0.159, 0.0148, 0.0162, 0.2016, 0.1573], [0.0941, 0.004, 0.0063, 0.2066, 0.0981]], [[0.1963, 0.1963, 0.1963, 0.1963, 0.1963], [0.2018, 0.1638, 0.0889, 0.2018, 0.2018], [0.1995, 0.0702, 0.0325, 0.1995, 0.1995], [0.179, 0.0226, 0.0109, 0.2, 0.1383], [0.1136, 0.0084, 0.0021, 0.2024, 0.0769]], [[0.1957, 0.1957, 0.1957, 0.1957, 0.1957], [0.2029, 0.1241, 0.1297, 0.2029, 0.2029], [0.2013, 0.0499, 0.0506, 0.2013, 0.2013], [0.184, 0.0181, 0.0157, 0.2045, 0.1384], [0.1145, 0.0048, 0.0049, 0.1956, 0.0725]], [[0.2079, 0.2079, 0.2079, 0.2079, 0.2079], [0.1992, 0.162, 0.0888, 0.1992, 0.1992], [0.1998, 0.0705, 0.0308, 0.1998, 0.1998], [0.1538, 0.0263, 0.0121, 0.1982, 0.1574], [0.0904, 0.0071, 0.0027, 0.1949, 0.0913]]]).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0050, 0.8025, 0.4125, 0.5550, 0.9750])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[0.26, 0.22, 0.06, 0.15, 0.31], [0.17, 0.25, 0.09, 0.2, 0.29], [0.34, 0.14, 0.2, 0.12, 0.2], [0.31, 0.31, 0.08, 0.1, 0.2], [0.26, 0.15, 0.12, 0.17, 0.3]])\n",
    "torch.sum(a,dim=0)*0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4383)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.Tensor([[0.26, 0.22, 0.06, 0.15, 0.31], [0.17, 0.25, 0.09, 0.2, 0.29], [0.34, 0.14, 0.2, 0.12, 0.2], [0.31, 0.31, 0.08, 0.1, 0.2], [0.26, 0.15, 0.12, 0.17, 0.3]])*theta*0.75)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy policy\n",
      "Available providers [[[0.2, 0.2, 0.2, 0.2, 0.2], [0.19999999999999998, 0.14977755808205634, 0.14908551655956498, 0.19999999999999998, 0.19999999999999998], [0.2, 0.09249512670565302, 0.10155945419103314, 0.2, 0.2], [0.1869187531936638, 0.06356668369954012, 0.06213592233009709, 0.2, 0.1884517118037813], [0.1616957605985037, 0.03940149625935162, 0.03551122194513716, 0.19999999999999998, 0.16349127182044887]], [[0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998], [0.19999999999999998, 0.14685242518059854, 0.15376676986584106, 0.19999999999999998, 0.19999999999999998], [0.2, 0.09835221421215243, 0.10010298661174047, 0.2, 0.2], [0.1875, 0.06071428571428571, 0.060119047619047614, 0.2, 0.18759920634920635], [0.162729912875121, 0.03591481122942885, 0.03727008712487899, 0.2, 0.16311713455953533]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.1734390485629336, 0.12348860257680871, 0.2, 0.2], [0.2, 0.12531328320802004, 0.07548872180451127, 0.2, 0.2], [0.1937, 0.0801, 0.0458, 0.2, 0.1817], [0.17391304347826086, 0.05039525691699605, 0.025197628458498024, 0.19999999999999998, 0.15079051383399208]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.14775751601774273, 0.15120749137506162, 0.2, 0.2], [0.2, 0.10034773969200199, 0.09975161450571288, 0.2, 0.2], [0.19422982885085574, 0.06141809290953545, 0.06376528117359412, 0.19999999999999998, 0.17955990220048898], [0.17443762781186095, 0.03680981595092025, 0.03680981595092025, 0.2, 0.1512269938650307]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.19999999999999998, 0.1752008032128514, 0.1282128514056225, 0.19999999999999998, 0.19999999999999998], [0.2, 0.127027027027027, 0.07497497497497498, 0.2, 0.2], [0.18668012108980828, 0.0798183652875883, 0.044803229061553984, 0.2, 0.18779011099899093], [0.16110826064648537, 0.05038481272447408, 0.025243714725500254, 0.19999999999999998, 0.16244227809132888]]]\n",
      "Top [[0.1242, 0.2727, 0.2738, 0.0422, 0.2871], [0.1271, 0.2662, 0.2808, 0.0463, 0.2796], [0.3023, 0.31, 0.235, 0.0429, 0.1098], [0.297, 0.2751, 0.2722, 0.0417, 0.114], [0.1193, 0.3194, 0.2417, 0.0457, 0.2739]]\n",
      "Selected [[0.0176, 0.0798, 0.2739, 0.0067, 0.1185], [0.0209, 0.0784, 0.2683, 0.006, 0.1228], [0.1271, 0.3174, 0.0429, 0.0071, 0.0096], [0.1318, 0.081, 0.2785, 0.007, 0.0081], [0.0196, 0.3181, 0.0417, 0.0055, 0.1163]]\n",
      "Prob [0.317  0.8747 0.9053 0.0323 0.3753]\n",
      "Took 2.1197967529296875 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.50092, 0.40952067682576077)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = greedy_policy\n",
    "name = \"greedy\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2**(num_patients*num_providers)*2**(num_patients)*math.factorial(num_patients) < 100000:\n",
    "    policy = one_shot_policy\n",
    "    per_epoch_function = optimal_policy\n",
    "    name = \"optimal\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_order policy\n",
      "Took 0.017654895782470703 time\n",
      "0.758 0.5405452364134852\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = optimal_order_policy\n",
    "name = \"optimal_order\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp policy\n",
      "Available providers [[[0.2, 0.2, 0.2, 0.2, 0.2], [0.1737024221453287, 0.1754819574888779, 0.17538309441423627, 0.17429560059317845, 0.19999999999999998], [0.14951267056530212, 0.14746588693957113, 0.15233918128654972, 0.14473684210526314, 0.2], [0.12825753704649975, 0.12427184466019418, 0.1246806336228922, 0.12386305569749619, 0.2], [0.09476309226932668, 0.10104738154613466, 0.10124688279301745, 0.10304239401496258, 0.19999999999999998]], [[0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998], [0.17863777089783278, 0.17523219814241484, 0.19999999999999998, 0.17162022703818366, 0.17512899896800824], [0.1513903192584964, 0.1486096807415036, 0.2, 0.1474768280123584, 0.1509783728115345], [0.12430555555555556, 0.12311507936507934, 0.2, 0.1251984126984127, 0.12331349206349204], [0.09903194578896418, 0.1021297192642788, 0.2, 0.09641819941916747, 0.10145208131655373]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.17413280475718534, 0.2, 0.17403369672943508, 0.1734390485629336, 0.1753221010901883], [0.14947368421052631, 0.2, 0.15238095238095237, 0.14887218045112782, 0.1500751879699248], [0.1232, 0.2, 0.12840000000000001, 0.1227, 0.127], [0.10128458498023715, 0.19999999999999998, 0.09555335968379446, 0.09891304347826087, 0.10454545454545454]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.1755544603252834, 0.174075899457861, 0.17220305569245936, 0.1771315919172006], [0.2, 0.1483358171882762, 0.1496274217585693, 0.15151515151515152, 0.15062096373571782], [0.19999999999999998, 0.12606356968215157, 0.12665036674816627, 0.12136919315403423, 0.12488997555012224], [0.2, 0.09703476482617587, 0.10552147239263805, 0.09969325153374234, 0.09703476482617587]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.1766064257028112, 0.1752008032128514, 0.1756024096385542, 0.19999999999999998, 0.17600401606425703], [0.15085085085085087, 0.15235235235235237, 0.15075075075075076, 0.2, 0.14804804804804805], [0.11977800201816347, 0.12199798183652877, 0.12906155398587288, 0.2, 0.1282542885973764], [0.0991277578245254, 0.09635710620831195, 0.10210364289379167, 0.19999999999999998, 0.10159055926115956]]]\n",
      "Top [[0.0332, 0.1624, 0.7535, 0.0091, 0.0418], [0.0347, 0.3688, 0.5036, 0.0097, 0.0832], [0.0938, 0.4959, 0.3751, 0.0098, 0.0254], [0.0478, 0.1613, 0.7556, 0.0093, 0.026], [0.0246, 0.7494, 0.1675, 0.0063, 0.0522]]\n",
      "Selected [[0.0, 0.0, 0.0, 0.0, 0.4965], [0.0, 0.0, 0.4964, 0.0, 0.0], [0.0, 0.5041, 0.0, 0.0, 0.0], [0.5064, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.5012, 0.0]]\n",
      "Prob [0.5064 0.5041 0.4964 0.5012 0.4965]\n",
      "Took 2.1808853149414062 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.50092, 0.3300156822761553, 6.3594630751922825)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_policy\n",
    "name = \"lp\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_workload policy\n",
      "Took 0.5431537628173828 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 6.892960645691221, 6.892960645691221)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_workload_policy\n",
    "name = \"lp_workload\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_multiple_match policy\n",
      "Took 0.09562230110168457 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2536, 0.23916547111746667)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_multiple_match_policy\n",
    "name = \"lp_multiple_match\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice_model == 'threshold':\n",
    "    policy = one_shot_policy \n",
    "    per_epoch_function = lp_threshold\n",
    "    name = \"lp_threshold\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_more_patients policy\n",
      "Took 0.6590728759765625 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = lp_more_patients_policy\n",
    "name = \"lp_more_patients\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_fairness policy\n",
      "Took 0.5672309398651123 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.4479570155876951)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_fairness_policy\n",
    "name = \"lp_fairness\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based policy\n",
      "Took 0.715339183807373 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_policy\n",
    "name = \"group_based\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based_unidirectional policy\n",
      "Took 0.7381973266601562 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7504, 0.5187739882075151)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_unidirectional_policy\n",
    "name = \"group_based_unidirectional\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused policy\n",
      "B 3, Per provider [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3.], Per Patient [1. 4. 1. 3. 4. 4. 3. 4. 2. 5. 1. 1. 2. 5. 2. 2. 3. 2. 4. 4. 5. 5. 1. 4.\n",
      " 3.]\n",
      "Took 0.1559138298034668 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6824, 0.511133744634547)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_policy\n",
    "name = \"provider_focused\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_less_interference policy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seed_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_705884/2735123428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} policy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_multi_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper_epoch_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}_matches'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed_list' is not defined"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_less_interference_policy\n",
    "name = \"provider_focused_less_interference\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_linear_regularization_0.25 policy\n",
      "B 1, Per provider [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [2. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "Took 0.03953838348388672 time\n",
      "0.25 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_0.5 policy\n",
      "B 1, Per provider [1. 0. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [1. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/patient_provider/patient/provider_policies.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  real_value += upper/lower*prod\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0397343635559082 time\n",
      "0.5 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_1 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.031838178634643555 time\n",
      "1 0.0 0.0\n",
      "provider_focused_linear_regularization_2 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03140616416931152 time\n",
      "2 0.0 0.0\n",
      "provider_focused_linear_regularization_4 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03318023681640625 time\n",
      "4 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# policy = one_shot_policy \n",
    "# for lamb in [0.25,0.5,1,2,4]:\n",
    "#     per_epoch_function = provider_focused_linear_regularization_policy(lamb)\n",
    "#     name = \"provider_focused_linear_regularization_{}\".format(lamb)\n",
    "#     print(\"{} policy\".format(name))\n",
    "\n",
    "#     rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "#     results['{}_matches'.format(name)] = rewards['matches']\n",
    "#     results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "#     results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "#     results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "#     results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "#     results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "#     results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "#     results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "#     results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "#     results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "#     print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = one_shot_policy \n",
    "# for lamb in [0,0.1,0.25,0.5]:#,1,2,4]:\n",
    "#     per_epoch_function = provider_focused_log_regularization_policy(lamb)\n",
    "#     name = \"provider_focused_log_regularization_{}\".format(lamb)\n",
    "#     print(\"{} policy\".format(name))\n",
    "\n",
    "#     rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "#     results['{}_matches'.format(name)] = rewards['matches']\n",
    "#     results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "#     results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "#     results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "#     results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "#     results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "#     results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "#     results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "#     results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "#     results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "#     print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = one_shot_policy \n",
    "# per_epoch_function = gradient_descent_policy\n",
    "# name = \"gradient_descent\"\n",
    "# print(\"{} policy\".format(name))\n",
    "\n",
    "# rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "# results['{}_matches'.format(name)] = rewards['matches']\n",
    "# results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "# results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "# results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "# results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "# results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "# results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "# results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "# results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "# results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "# print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent_2 policy\n",
      "Available providers [[[0.2, 0.2, 0.2, 0.2, 0.2], [0.19999999999999998, 0.14977755808205634, 0.14908551655956498, 0.19999999999999998, 0.19999999999999998], [0.2, 0.09249512670565302, 0.10155945419103314, 0.2, 0.2], [0.1869187531936638, 0.06356668369954012, 0.06213592233009709, 0.2, 0.1884517118037813], [0.1616957605985037, 0.03940149625935162, 0.03551122194513716, 0.19999999999999998, 0.16349127182044887]], [[0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998], [0.19999999999999998, 0.14685242518059854, 0.15376676986584106, 0.19999999999999998, 0.19999999999999998], [0.2, 0.09835221421215243, 0.10010298661174047, 0.2, 0.2], [0.1875, 0.06071428571428571, 0.060119047619047614, 0.2, 0.18759920634920635], [0.162729912875121, 0.03591481122942885, 0.03727008712487899, 0.2, 0.16311713455953533]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.1734390485629336, 0.12348860257680871, 0.2, 0.2], [0.2, 0.12531328320802004, 0.07548872180451127, 0.2, 0.2], [0.1937, 0.0801, 0.0458, 0.2, 0.1817], [0.17391304347826086, 0.05039525691699605, 0.025197628458498024, 0.19999999999999998, 0.15079051383399208]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.14775751601774273, 0.15120749137506162, 0.2, 0.2], [0.2, 0.10034773969200199, 0.09975161450571288, 0.2, 0.2], [0.19422982885085574, 0.06141809290953545, 0.06376528117359412, 0.19999999999999998, 0.17955990220048898], [0.17443762781186095, 0.03680981595092025, 0.03680981595092025, 0.2, 0.1512269938650307]], [[0.2, 0.2, 0.2, 0.2, 0.2], [0.19999999999999998, 0.1752008032128514, 0.1282128514056225, 0.19999999999999998, 0.19999999999999998], [0.2, 0.127027027027027, 0.07497497497497498, 0.2, 0.2], [0.18668012108980828, 0.0798183652875883, 0.044803229061553984, 0.2, 0.18779011099899093], [0.16110826064648537, 0.05038481272447408, 0.025243714725500254, 0.19999999999999998, 0.16244227809132888]]]\n",
      "Top [[0.1242, 0.2727, 0.2738, 0.0422, 0.2871], [0.1271, 0.2662, 0.2808, 0.0463, 0.2796], [0.3023, 0.31, 0.235, 0.0429, 0.1098], [0.297, 0.2751, 0.2722, 0.0417, 0.114], [0.1193, 0.3194, 0.2417, 0.0457, 0.2739]]\n",
      "Selected [[0.0176, 0.0798, 0.2739, 0.0067, 0.1185], [0.0209, 0.0784, 0.2683, 0.006, 0.1228], [0.1271, 0.3174, 0.0429, 0.0071, 0.0096], [0.1318, 0.081, 0.2785, 0.007, 0.0081], [0.0196, 0.3181, 0.0417, 0.0055, 0.1163]]\n",
      "Prob [0.317  0.8747 0.9053 0.0323 0.3753]\n",
      "Took 2.217886447906494 time\n",
      "0.50092 0.40952067682576077\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = gradient_descent_policy_2\n",
    "name = \"gradient_descent_2\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective2(z, theta, p, sorted_theta,lamb=1, smooth_reg='entropy', epsilon=1e-5):\n",
    "    x = torch.sigmoid(z)\n",
    "        \n",
    "    rows_with_top_i = torch.zeros((theta.shape[1], theta.shape[0]), device=theta.device)\n",
    "    argsorted = torch.argsort(theta, dim=1, descending=True)\n",
    "\n",
    "    # Mask elements in `argsorted` where x is 0\n",
    "    mask = x.gather(1, argsorted) != 0\n",
    "\n",
    "    # Filter out -1 indices\n",
    "    filtered_argsorted = [\n",
    "        torch.masked_select(argsorted[i], mask[i]) for i in range(len(argsorted))\n",
    "    ]\n",
    "    is_top_k = torch.zeros((theta.shape[0], theta.shape[1], theta.shape[0]), device=theta.device)\n",
    "\n",
    "    # We need to update rows_with_top_i for each provider from their rank onwards\n",
    "    for patient in range(len(filtered_argsorted)):\n",
    "        # For each provider at the current rank\n",
    "        for rank in range(len(filtered_argsorted[patient])):\n",
    "            provider = filtered_argsorted[patient][rank]\n",
    "            # Update rows_with_top_i for this provider starting from the current rank onwards\n",
    "            rows_with_top_i[provider, rank:] += 1\n",
    "            is_top_k[patient,provider,rank:] +=  1 / (theta.shape[0] - 1)\n",
    "\n",
    "\n",
    "    # Normalize rows_with_top_i\n",
    "    rows_with_top_i /= (theta.shape[0] - 1)\n",
    "\n",
    "    # Step 4: Normalize `x`\n",
    "    normalized_x = torch.zeros_like(x)\n",
    "    delta = rows_with_top_i[None, :, :] - is_top_k\n",
    "    delta = torch.roll(delta, shifts=1, dims=2)  # Shift columns to the right (dims=2 corresponds to columns)\n",
    "    delta[:, :, 0] = 0  # Set the leftmost column to 1\n",
    "\n",
    "    # TODO: Remove this\n",
    "    \n",
    "\n",
    "    delta = 1-p*delta\n",
    "    delta_raised = torch.cumprod(delta,dim=2)\n",
    "    # Raise delta to successive powers along the third dimension\n",
    "    delta_swapped = delta_raised.permute(0, 2, 1)\n",
    "\n",
    "    normalized_x = x[:,None,:] * delta_swapped\n",
    "\n",
    "    sorted_normalized_x = normalized_x.gather(dim=2, index=sorted_theta.unsqueeze(1).expand(-1, normalized_x.size(1), -1))\n",
    "\n",
    "    # Compute cumulative products (1 - normalized_x) along rows\n",
    "    one_minus_sorted = 1 - sorted_normalized_x\n",
    "    cumprods = torch.cumprod(one_minus_sorted, dim=2)\n",
    "\n",
    "    # # Shift the cumulative products to use for the original scaling (prepending 1 for first index)\n",
    "    shifted_cumprods = torch.cat([torch.ones(cumprods.size(0), cumprods.size(1) ,1,device=cumprods.device), cumprods[:,:,:-1]], dim=2)\n",
    "\n",
    "\n",
    "    # Apply the cumulative product scaling to the original indices\n",
    "    scaled_normalized_x = sorted_normalized_x * shifted_cumprods\n",
    "    scaled_normalized_x = torch.mean(scaled_normalized_x,dim=1)\n",
    "\n",
    "    # Scatter back to the original positions\n",
    "    normalized_x = torch.zeros_like(scaled_normalized_x)\n",
    "    normalized_x.scatter_(1, sorted_theta, scaled_normalized_x)\n",
    "    # Normalize row-wise\n",
    "    # Compute numerator for the first term (using normalized x)\n",
    "    term = p * torch.sum(normalized_x * theta, dim=0)\n",
    "        \n",
    "    term = torch.sum(term) / theta.shape[1]  # Normalize by number of columns\n",
    "\n",
    "    reg_term = 0\n",
    "    # Add smooth regularization term\n",
    "    if smooth_reg == 'logit' and lamb > 0:\n",
    "        reg_term = torch.sum(torch.logit(x, eps=epsilon) ** 2)  # Logit-based penalty\n",
    "    elif smooth_reg == 'entropy' and lamb > 0:\n",
    "        reg_term = -torch.sum(x * torch.log(x + epsilon) + (1 - x) * torch.log(1 - x + epsilon))  # Entropy-based penalty\n",
    "    loss = term - lamb * reg_term\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter:\n",
    "    theta = [p.provider_rewards for p in simulator.patients]\n",
    "    theta = torch.Tensor(theta)\n",
    "    sorted_theta = torch.argsort(theta, dim=1,descending=True)  # Sorting indices of `theta` row-wise\n",
    "    opt_tensor = torch.Tensor(lp_policy(simulator))\n",
    "    ones_tensor = torch.Tensor(np.ones(opt_tensor.shape))\n",
    "    x = torch.Tensor(gradient_descent_policy_2(simulator))\n",
    "    p = true_top_choice_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.Tensor(np.ones((5,5)))\n",
    "theta -= torch.Tensor([[j/1000 for j in range(5)] for i in range(5)])\n",
    "sorted_theta = torch.argsort(theta, dim=1,descending=True)\n",
    "p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta is tensor([1., 0., 0., 0., 0.])\n",
      "tensor([[0.2000, 0.4000, 0.6000, 0.8000, 1.0000],\n",
      "        [0.2000, 0.4000, 0.6000, 0.8000, 1.0000],\n",
      "        [0.2000, 0.4000, 0.6000, 0.8000, 1.0000],\n",
      "        [0.2000, 0.4000, 0.6000, 0.8000, 1.0000],\n",
      "        [0.2000, 0.4000, 0.6000, 0.8000, 1.0000]])\n",
      "tensor(0.9980)\n",
      "Delta is tensor([1.0000, 0.7500, 0.5625, 0.4219, 0.3164])\n",
      "tensor([[0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "tensor(0.9980)\n"
     ]
    }
   ],
   "source": [
    "if is_jupyter:\n",
    "    print(objective2(ones_tensor*10000-10000/2,theta,p,sorted_theta,0))\n",
    "    # print(objective2(x*10000-10000/2,theta,p,sorted_theta,0))\n",
    "    print(objective2(opt_tensor*10000-10000/2,theta,p,sorted_theta,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../../results/'+save_path,'w'),cls=MyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
