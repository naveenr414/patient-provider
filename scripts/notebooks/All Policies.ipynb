{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import secrets\n",
    "import json\n",
    "import sys\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patient.simulator import run_multi_seed\n",
    "from patient.baseline_policies import *\n",
    "from patient.lp_policies import *\n",
    "from patient.group_based_policies import *\n",
    "from patient.ordering_policies import *\n",
    "from patient.provider_policies import *\n",
    "from patient.utils import get_save_path, delete_duplicate_results, restrict_resources, one_shot_policy, MyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 45\n",
    "    num_patients = 3\n",
    "    num_providers = 3\n",
    "    provider_capacity = 1\n",
    "    top_choice_prob = 0.5\n",
    "    true_top_choice_prob = 0.5\n",
    "    choice_model = \"uniform_choice\"\n",
    "    exit_option = 0.5\n",
    "    utility_function = \"normal\"\n",
    "    out_folder = \"policy_comparison\"\n",
    "    num_repetitions = 1\n",
    "    num_trials = 100\n",
    "    context_dim = 5\n",
    "    max_menu_size = 25\n",
    "    previous_patients_per_provider = 10\n",
    "    order=\"custom\"\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', help='Random Seed', type=int, default=42)\n",
    "    parser.add_argument('--n_patients',         '-N', help='Number of patients', type=int, default=100)\n",
    "    parser.add_argument('--n_providers',        help='Number of providers', type=int, default=100)\n",
    "    parser.add_argument('--n_trials',          help='Number of trials ', type=int, default=2)\n",
    "    parser.add_argument('--top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--true_top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--context_dim',          help='Context dim for patients and providers', type=int, default=5)\n",
    "    parser.add_argument('--max_menu_size',          help='Context dim for patients and providers', type=int, default=50)\n",
    "    parser.add_argument('--num_repetitions',          help='Context dim for patients and providers', type=int, default=1)\n",
    "    parser.add_argument('--previous_patients_per_provider',          help='Context dim for patients and providers', type=int, default=10)\n",
    "    parser.add_argument('--provider_capacity', help='Provider Capacity', type=int, default=5)\n",
    "    parser.add_argument('--choice_model', help='Which choice model for patients', type=str, default='uniform_choice')\n",
    "    parser.add_argument('--exit_option', help='What is the value of the exit option', type=float, default=0.5)\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='policy_comparison')\n",
    "    parser.add_argument('--utility_function', help='Which folder to write results to', type=str, default='uniform')\n",
    "    parser.add_argument('--order', help='Which folder to write results to', type=str, default='random')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    seed = args.seed\n",
    "    num_patients = args.n_patients\n",
    "    num_providers = args.n_providers \n",
    "    provider_capacity = args.provider_capacity\n",
    "    top_choice_prob = args.top_choice_prob\n",
    "    choice_model = args.choice_model\n",
    "    exit_option = args.exit_option\n",
    "    out_folder = args.out_folder\n",
    "    num_trials = args.n_trials \n",
    "    context_dim = args.context_dim \n",
    "    num_repetitions = args.num_repetitions\n",
    "    true_top_choice_prob = args.true_top_choice_prob\n",
    "    max_menu_size = args.max_menu_size\n",
    "    utility_function = args.utility_function\n",
    "    order = args.order\n",
    "    previous_patients_per_provider = args.previous_patients_per_provider\n",
    "\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'num_patients'    : num_patients,\n",
    "        'num_providers': num_providers, \n",
    "        'provider_capacity'    : provider_capacity,\n",
    "        'top_choice_prob': top_choice_prob, \n",
    "        'choice_model': choice_model,\n",
    "        'exit_option': exit_option,\n",
    "        'num_trials': num_trials,\n",
    "        'context_dim': context_dim, \n",
    "        'true_top_choice_prob': true_top_choice_prob, \n",
    "        'num_repetitions': num_repetitions, \n",
    "        'max_menu_size': max_menu_size, \n",
    "        'utility_function': utility_function, \n",
    "        'order': order, \n",
    "        'previous_patients_per_provider': previous_patients_per_provider} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [seed]\n",
    "restrict_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random policy\n",
      "[[86. 87. 85.]\n",
      " [84. 85. 77.]\n",
      " [91. 88. 76.]]\n",
      "Selected b [[ 7. 13. 28.]\n",
      " [ 9. 11. 15.]\n",
      " [20. 10. 15.]]\n",
      "Probs [36. 34. 58.]\n",
      "[[0.33333333 0.3372093  0.32945736]\n",
      " [0.34146341 0.34552846 0.31300813]\n",
      " [0.35686275 0.34509804 0.29803922]]\n",
      "Took 0.012576580047607422 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4266666666666667, 0.20274417329776181)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = random_policy\n",
    "name = \"random\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_repetitions*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_repetitions*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy_basic policy\n",
      "[[ 96.  98.  61.]\n",
      " [ 91.  95.  53.]\n",
      " [100.  91.  56.]]\n",
      "Selected b [[ 0. 17. 38.]\n",
      " [ 4. 19. 27.]\n",
      " [25.  0. 28.]]\n",
      "Probs [29. 36. 93.]\n",
      "[[0.37647059 0.38431373 0.23921569]\n",
      " [0.38075314 0.39748954 0.22175732]\n",
      " [0.4048583  0.36842105 0.22672065]]\n",
      "Took 0.014554738998413086 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.47528123424177965, 0.3343630816816568, 0.05650264512585234)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = all_ones_policy\n",
    "name = \"greedy_basic\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.mean(results['{}_minimums_all'.format(name)]),np.mean(results['{}_gaps_all'.format(name)]),np.mean(results['{}_variance_all'.format(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy policy\n",
      "[[ 96.  98.  61.]\n",
      " [ 91.  95.  53.]\n",
      " [100.  91.  56.]]\n",
      "Selected b [[ 0. 17. 38.]\n",
      " [ 4. 19. 27.]\n",
      " [25.  0. 28.]]\n",
      "Probs [29. 36. 93.]\n",
      "[[0.37647059 0.38431373 0.23921569]\n",
      " [0.38075314 0.39748954 0.22175732]\n",
      " [0.4048583  0.36842105 0.22672065]]\n",
      "Took 0.015651226043701172 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5266666666666666, 0.308094822039019)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = greedy_policy\n",
    "name = \"greedy\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2+5+44)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2**(num_patients*num_providers)*2**(num_patients)*math.factorial(num_patients) < 100000:\n",
    "    policy = one_shot_policy\n",
    "    per_epoch_function = optimal_policy\n",
    "    name = \"optimal\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_order policy\n",
      "Took 0.017654895782470703 time\n",
      "0.758 0.5405452364134852\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = optimal_order_policy\n",
    "name = \"optimal_order\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp policy\n",
      "[[100.  81.  74.]\n",
      " [ 67. 100.  72.]\n",
      " [ 70.  77. 100.]]\n",
      "Selected b [[55.  0.  0.]\n",
      " [ 0. 50.  0.]\n",
      " [ 0.  0. 53.]]\n",
      "Probs [55. 50. 53.]\n",
      "[[0.39215686 0.31764706 0.29019608]\n",
      " [0.28033473 0.41841004 0.30125523]\n",
      " [0.28340081 0.31174089 0.4048583 ]]\n",
      "Took 0.0103912353515625 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/patient_provider/patient/simulator.py:400: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  scores['provider_minimums'].append(min_utilities)\n",
      "/usr0/home/naveenr/projects/patient_provider/patient/simulator.py:404: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  scores['provider_gaps_all'].append(max_gap_all)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5266666666666666, 0.22146249983425478, 6.687514900169334)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_policy\n",
    "name = \"lp\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_workload policy\n",
      "Took 0.5431537628173828 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 6.892960645691221, 6.892960645691221)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_workload_policy\n",
    "name = \"lp_workload\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_multiple_match policy\n",
      "Took 0.09562230110168457 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2536, 0.23916547111746667)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_multiple_match_policy\n",
    "name = \"lp_multiple_match\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice_model == 'threshold':\n",
    "    policy = one_shot_policy \n",
    "    per_epoch_function = lp_threshold\n",
    "    name = \"lp_threshold\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_more_patients policy\n",
      "Took 0.6590728759765625 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = lp_more_patients_policy\n",
    "name = \"lp_more_patients\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_fairness policy\n",
      "Took 0.5672309398651123 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.4479570155876951)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_fairness_policy\n",
    "name = \"lp_fairness\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based policy\n",
      "Took 0.715339183807373 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_policy\n",
    "name = \"group_based\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based_unidirectional policy\n",
      "Took 0.7381973266601562 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7504, 0.5187739882075151)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_unidirectional_policy\n",
    "name = \"group_based_unidirectional\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused policy\n",
      "B 3, Per provider [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3.], Per Patient [1. 4. 1. 3. 4. 4. 3. 4. 2. 5. 1. 1. 2. 5. 2. 2. 3. 2. 4. 4. 5. 5. 1. 4.\n",
      " 3.]\n",
      "Took 0.1559138298034668 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6824, 0.511133744634547)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_policy\n",
    "name = \"provider_focused\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_less_interference policy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seed_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_705884/2735123428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} policy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_multi_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper_epoch_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}_matches'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed_list' is not defined"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_less_interference_policy\n",
    "name = \"provider_focused_less_interference\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_linear_regularization_0.25 policy\n",
      "B 1, Per provider [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [2. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "Took 0.03953838348388672 time\n",
      "0.25 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_0.5 policy\n",
      "B 1, Per provider [1. 0. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [1. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/patient_provider/patient/provider_policies.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  real_value += upper/lower*prod\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0397343635559082 time\n",
      "0.5 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_1 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.031838178634643555 time\n",
      "1 0.0 0.0\n",
      "provider_focused_linear_regularization_2 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03140616416931152 time\n",
      "2 0.0 0.0\n",
      "provider_focused_linear_regularization_4 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03318023681640625 time\n",
      "4 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# policy = one_shot_policy \n",
    "# for lamb in [0.25,0.5,1,2,4]:\n",
    "#     per_epoch_function = provider_focused_linear_regularization_policy(lamb)\n",
    "#     name = \"provider_focused_linear_regularization_{}\".format(lamb)\n",
    "#     print(\"{} policy\".format(name))\n",
    "\n",
    "#     rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "#     results['{}_matches'.format(name)] = rewards['matches']\n",
    "#     results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "#     results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "#     results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "#     results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "#     results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "#     results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "#     results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "#     results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "#     results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "#     print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = one_shot_policy \n",
    "# for lamb in [0,0.1,0.25,0.5]:#,1,2,4]:\n",
    "#     per_epoch_function = provider_focused_log_regularization_policy(lamb)\n",
    "#     name = \"provider_focused_log_regularization_{}\".format(lamb)\n",
    "#     print(\"{} policy\".format(name))\n",
    "\n",
    "#     rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "#     results['{}_matches'.format(name)] = rewards['matches']\n",
    "#     results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "#     results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "#     results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "#     results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "#     results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "#     results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "#     results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "#     results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "#     results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "#     print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = one_shot_policy \n",
    "# per_epoch_function = gradient_descent_policy\n",
    "# name = \"gradient_descent\"\n",
    "# print(\"{} policy\".format(name))\n",
    "\n",
    "# rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "# results['{}_matches'.format(name)] = rewards['matches']\n",
    "# results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "# results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "# results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "# results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "# results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "# results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "# results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "# results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "# results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "# print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent_2 policy\n",
      "[[100. 100.  61.]\n",
      " [100. 100.  53.]\n",
      " [100. 100.  56.]]\n",
      "Selected b [[ 0.  0. 38.]\n",
      " [ 0.  0. 27.]\n",
      " [ 0.  0. 28.]]\n",
      "Probs [ 0.  0. 93.]\n",
      "[[0.38314176 0.38314176 0.23371648]\n",
      " [0.39525692 0.39525692 0.20948617]\n",
      " [0.390625   0.390625   0.21875   ]]\n",
      "Took 0.010378122329711914 time\n",
      "0.31 0.2698814386411455\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = gradient_descent_policy_2\n",
    "name = \"gradient_descent_2\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective2(z, theta, p, sorted_theta,lamb=1, smooth_reg='entropy', epsilon=1e-5):\n",
    "    # Reparameterize x using sigmoid\n",
    "    x = torch.sigmoid(z)  # x is now bounded in [0, 1]\n",
    "    \n",
    "    # TODO: Maybe it should be dim=1 again\n",
    "    row_sums = torch.sum(x, dim=0, keepdim=True)  # Shape: (rows, 1)\n",
    "    \n",
    "    # Normalize x by row sums\n",
    "    normalized_x = x / (p*torch.maximum(row_sums, torch.tensor(1.0, device=x.device)))*(1-(1-p)**(torch.maximum(row_sums, torch.tensor(1.0, device=x.device)))) \n",
    "\n",
    "    sorted_normalized_x = normalized_x.gather(1, sorted_theta)\n",
    "\n",
    "    # Compute cumulative products (1 - normalized_x) along rows\n",
    "    one_minus_sorted = 1 - sorted_normalized_x\n",
    "    cumprods = torch.cumprod(one_minus_sorted, dim=1)\n",
    "\n",
    "    # Shift the cumulative products to use for the original scaling (prepending 1 for first index)\n",
    "    shifted_cumprods = torch.cat([torch.ones(cumprods.size(0), 1, device=cumprods.device), cumprods[:, :-1]], dim=1)\n",
    "\n",
    "    # Apply the cumulative product scaling to the original indices\n",
    "    scaled_normalized_x = sorted_normalized_x * shifted_cumprods\n",
    "\n",
    "    # Scatter back to the original positions\n",
    "    normalized_x = torch.zeros_like(normalized_x)\n",
    "    normalized_x.scatter_(1, sorted_theta, scaled_normalized_x)\n",
    "    # Normalize row-wise\n",
    "\n",
    "    print(\"Top available {}\".format(normalized_x))\n",
    "\n",
    "    prod = p*torch.sum(normalized_x,dim=0)\n",
    "\n",
    "    print(\"Prod {}\".format(prod))\n",
    "\n",
    "    # Compute numerator for the first term (using normalized x)\n",
    "    term1_num = prod * torch.sum(normalized_x * theta, dim=0)\n",
    "\n",
    "    term1_den = torch.sum(normalized_x, dim=0) + 1e-8  # Avoid division by zero\n",
    "    term1_den = torch.maximum(term1_den,torch.tensor(1.0, device=x.device))\n",
    "\n",
    "    # Compute the main term\n",
    "    term1 = (term1_num / term1_den)\n",
    "        \n",
    "    term1 = torch.sum(term1) / theta.shape[1]  # Normalize by number of columns\n",
    "\n",
    "    reg_term = 0\n",
    "    # Add smooth regularization term\n",
    "    if smooth_reg == 'logit' and lamb > 0:\n",
    "        reg_term = torch.sum(torch.logit(x, eps=epsilon) ** 2)  # Logit-based penalty\n",
    "    elif smooth_reg == 'entropy' and lamb > 0:\n",
    "        reg_term = -torch.sum(x * torch.log(x + epsilon) + (1 - x) * torch.log(1 - x + epsilon))  # Entropy-based penalty\n",
    "    loss = term1 - lamb * reg_term\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter:\n",
    "    theta = [p.provider_rewards for p in simulator.patients]\n",
    "    theta = torch.Tensor(theta)\n",
    "    sorted_theta = torch.argsort(theta, dim=1,descending=True)  # Sorting indices of `theta` row-wise\n",
    "    opt_tensor = torch.Tensor(lp_policy(simulator))\n",
    "    ones_tensor = torch.Tensor(np.ones(opt_tensor.shape))\n",
    "    x = torch.Tensor(gradient_descent_policy_2(simulator))\n",
    "    p = true_top_choice_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top available tensor([[0.0000, 0.0000, 0.5833],\n",
      "        [0.0000, 0.0000, 0.5833],\n",
      "        [0.0000, 0.0000, 0.5833]])\n",
      "Prod tensor([0.0000, 0.0000, 0.8750])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sum_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1173371/855354270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_jupyter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# print(objective2(ones_tensor*10000-10000/2,theta,p,sorted_theta,0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorted_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1173371/3793308819.py\u001b[0m in \u001b[0;36mobjective2\u001b[0;34m(z, theta, p, sorted_theta, lamb, smooth_reg, epsilon)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mterm1_den\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-8\u001b[0m  \u001b[0;31m# Avoid division by zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mterm1_den\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm1_den\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Compute the main term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sum_x' is not defined"
     ]
    }
   ],
   "source": [
    "if is_jupyter:\n",
    "    # print(objective2(ones_tensor*10000-10000/2,theta,p,sorted_theta,0))\n",
    "    print(objective2(x*10000-10000/2,theta,p,sorted_theta,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3497661085.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1173371/3497661085.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    0.6100+0.5300+0.5600)/2\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644578500567125"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(1-0.5*.5833)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26577201943975615, 0.702677613146134)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-0.5**(.2431+.1013+.1013),1-0.5**(.5833+.5833+.5833)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_x = np.array([[0. ,        0.30909091, 0.69090909],\n",
    " [0.08   ,    0.38 ,      0.54      ],\n",
    " [0.47169811, 0.   ,      0.52830189]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../../results/'+save_path,'w'),cls=MyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
