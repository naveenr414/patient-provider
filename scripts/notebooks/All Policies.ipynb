{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr0/home/naveenr/projects/patient_provider')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import secrets\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patient.simulator import run_multi_seed\n",
    "from patient.baseline_policies import random_policy, greedy_policy\n",
    "from patient.online_policies import p_approximation, p_approximation_balance, p_approximation_with_additions, p_approximation_with_additions_balance, p_approximation_with_additions_balance_learning, solve_linear_program\n",
    "from patient.offline_policies import offline_solution, offline_solution_balance, offline_learning_solution\n",
    "from patient.utils import get_save_path, delete_duplicate_results, restrict_resources\n",
    "from patient.learning import guess_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 43\n",
    "    num_patients = 20\n",
    "    num_providers = 20\n",
    "    provider_capacity = 1\n",
    "    top_choice_prob = 0.5\n",
    "    choice_model = \"uniform_choice\"\n",
    "    out_folder = \"policy_comparison\"\n",
    "    exit_option = 0.5\n",
    "    num_trials = 1\n",
    "    context_dim = 5\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', help='Random Seed', type=int, default=42)\n",
    "    parser.add_argument('--n_patients',         '-N', help='Number of patients', type=int, default=100)\n",
    "    parser.add_argument('--n_providers',        help='Number of providers', type=int, default=100)\n",
    "    parser.add_argument('--n_trials',          help='Number of trials ', type=int, default=2)\n",
    "    parser.add_argument('--top_choice_prob',          help='Probability of picking top choice', type=float, default=0.8)\n",
    "    parser.add_argument('--context_dim',          help='Context dim for patients and providers', type=int, default=5)\n",
    "    parser.add_argument('--provider_capacity', help='Provider Capacity', type=int, default=5)\n",
    "    parser.add_argument('--choice_model', help='Which choice model for patients', type=str, default='uniform_choice')\n",
    "    parser.add_argument('--exit_option', help='What is the value of the exit option', type=float, default=0.5)\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='policy_comparison')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    seed = args.seed\n",
    "    num_patients = args.n_patients\n",
    "    num_providers = args.n_providers \n",
    "    provider_capacity = args.provider_capacity\n",
    "    top_choice_prob = args.top_choice_prob\n",
    "    choice_model = args.choice_model\n",
    "    exit_option = args.exit_option\n",
    "    out_folder = args.out_folder\n",
    "    num_trials = args.n_trials \n",
    "    context_dim = args.context_dim \n",
    "\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'num_patients'    : num_patients,\n",
    "        'num_providers': num_providers, \n",
    "        'provider_capacity'    : provider_capacity,\n",
    "        'top_choice_prob': top_choice_prob, \n",
    "        'choice_model': choice_model,\n",
    "        'exit_option': exit_option,\n",
    "        'num_trials': num_trials,\n",
    "        'context_dim': context_dim} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [seed]\n",
    "restrict_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0007159709930419922 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.45, 0.35719264099432857, 0.49749371855331)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = random_policy\n",
    "name = \"random\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0006170272827148438 time\n",
      "Took 0.00044727325439453125 time\n",
      "Took 0.0005402565002441406 time\n",
      "Took 0.0004057884216308594 time\n",
      "Took 0.0005731582641601562 time\n",
      "Took 0.0007159709930419922 time\n",
      "Took 0.0006372928619384766 time\n",
      "Took 0.0005412101745605469 time\n",
      "Took 0.0005543231964111328 time\n",
      "Took 0.0005390644073486328 time\n",
      "Took 0.0005414485931396484 time\n",
      "Took 0.0005545616149902344 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4583333333333333, 0.38864224355835514, 0.4982608642958916)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = greedy_policy\n",
    "name = \"greedy\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.033118486404418945 time\n",
      "Took 0.013564348220825195 time\n",
      "Took 0.013570547103881836 time\n",
      "Took 0.013626813888549805 time\n",
      "Took 0.01407170295715332 time\n",
      "Took 0.013982057571411133 time\n",
      "Took 0.013829946517944336 time\n",
      "Took 0.013564825057983398 time\n",
      "Took 0.013807058334350586 time\n",
      "Took 0.013852834701538086 time\n",
      "Took 0.01365351676940918 time\n",
      "Took 0.013617277145385742 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4583333333333333, 0.3832011236896941, 0.4982608642958916)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = p_approximation\n",
    "name = \"p_approximation\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.036939382553100586 time\n",
      "Took 0.017308473587036133 time\n",
      "Took 0.01694011688232422 time\n",
      "Took 0.018248319625854492 time\n",
      "Took 0.016951322555541992 time\n",
      "Took 0.01711440086364746 time\n",
      "Took 0.017180919647216797 time\n",
      "Took 0.01708531379699707 time\n",
      "Took 0.01707005500793457 time\n",
      "Took 0.01686835289001465 time\n",
      "Took 0.01725482940673828 time\n",
      "Took 0.01715874671936035 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4583333333333333, 0.3832011236896941, 0.4982608642958916)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = p_approximation_balance\n",
    "name = \"p_approximation_balance\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.035620927810668945 time\n",
      "Took 0.015419483184814453 time\n",
      "Took 0.015078544616699219 time\n",
      "Took 0.016537189483642578 time\n",
      "Took 0.015310049057006836 time\n",
      "Took 0.015996217727661133 time\n",
      "Took 0.015866756439208984 time\n",
      "Took 0.015033960342407227 time\n",
      "Took 0.01538228988647461 time\n",
      "Took 0.015430212020874023 time\n",
      "Took 0.01540684700012207 time\n",
      "Took 0.01485896110534668 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4583333333333333, 0.3856716890170183, 0.4982608642958916)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = p_approximation_with_additions\n",
    "name = \"p_approximation_additions\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.03577613830566406 time\n",
      "Took 0.018560409545898438 time\n",
      "Took 0.01870417594909668 time\n",
      "Took 0.019297361373901367 time\n",
      "Took 0.018475055694580078 time\n",
      "Took 0.019321918487548828 time\n",
      "Took 0.019361495971679688 time\n",
      "Took 0.01893472671508789 time\n",
      "Took 0.018806934356689453 time\n",
      "Took 0.019270658493041992 time\n",
      "Took 0.018843889236450195 time\n",
      "Took 0.018593311309814453 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4583333333333333, 0.3856716890170183, 0.4982608642958916)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = p_approximation_with_additions_balance\n",
    "name = \"p_approximation_additions_balance\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.03954935073852539 time\n",
      "Took 0.02138805389404297 time\n",
      "Took 0.02159714698791504 time\n",
      "Took 0.020982742309570312 time\n",
      "Took 0.0206601619720459 time\n",
      "Took 0.021484375 time\n",
      "Took 0.021408557891845703 time\n",
      "Took 0.021071195602416992 time\n",
      "Took 0.020660400390625 time\n",
      "Took 0.021979093551635742 time\n",
      "Took 0.020539045333862305 time\n",
      "Took 0.020846128463745117 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4583333333333333, 0.3840566057323451, 0.4982608642958916)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = p_approximation_with_additions_balance_learning\n",
    "name = \"p_approximation_additions_balance_learning\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.033345937728881836 time\n",
      "Took 0.013553619384765625 time\n",
      "Took 0.01352071762084961 time\n",
      "Took 0.014617443084716797 time\n",
      "Took 0.013826370239257812 time\n",
      "Took 0.01385045051574707 time\n",
      "Took 0.013760566711425781 time\n",
      "Took 0.01364755630493164 time\n",
      "Took 0.013838529586791992 time\n",
      "Took 0.01374959945678711 time\n",
      "Took 0.013604164123535156 time\n",
      "Took 0.01357579231262207 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4583333333333333, 0.386520047757149, 0.4982608642958916)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = offline_solution\n",
    "name = \"offline_solution\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.033899545669555664 time\n",
      "Took 0.01584768295288086 time\n",
      "Took 0.01600050926208496 time\n",
      "Took 0.016603469848632812 time\n",
      "Took 0.016025066375732422 time\n",
      "Took 0.016068220138549805 time\n",
      "Took 0.01612710952758789 time\n",
      "Took 0.01610875129699707 time\n",
      "Took 0.01608586311340332 time\n",
      "Took 0.01612401008605957 time\n",
      "Took 0.015980958938598633 time\n",
      "Took 0.016010522842407227 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4583333333333333, 0.386191144921408, 0.4982608642958916)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = offline_learning_solution\n",
    "name = \"offline_learning_solution\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.021645545959472656 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7, 0.49744308228226697, 0.45825756949558405)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = offline_solution_balance\n",
    "name = \"offline_solution_balance\"\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "np.mean(rewards['matches'])/(num_patients*num_trials),np.mean(rewards['patient_utilities'])/(num_patients*num_trials),np.std(rewards['provider_workloads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../../results/'+save_path,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
