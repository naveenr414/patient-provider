{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import secrets\n",
    "import json\n",
    "import sys\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patient.simulator import run_multi_seed\n",
    "from patient.baseline_policies import *\n",
    "from patient.lp_policies import *\n",
    "from patient.group_based_policies import *\n",
    "from patient.ordering_policies import *\n",
    "from patient.provider_policies import *\n",
    "from patient.utils import get_save_path, delete_duplicate_results, restrict_resources, one_shot_policy, MyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 43\n",
    "    num_patients = 5\n",
    "    num_providers = 5\n",
    "    provider_capacity = 1\n",
    "    top_choice_prob = 0.75\n",
    "    true_top_choice_prob = 0.75\n",
    "    choice_model = \"uniform_choice\"\n",
    "    exit_option = 0.5\n",
    "    utility_function = \"normal\"\n",
    "    out_folder = \"policy_comparison\"\n",
    "    num_repetitions = 1\n",
    "    num_trials = 100\n",
    "    context_dim = 5\n",
    "    max_menu_size = 25\n",
    "    previous_patients_per_provider = 10\n",
    "    order=\"custom\"\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', help='Random Seed', type=int, default=42)\n",
    "    parser.add_argument('--n_patients',         '-N', help='Number of patients', type=int, default=100)\n",
    "    parser.add_argument('--n_providers',        help='Number of providers', type=int, default=100)\n",
    "    parser.add_argument('--n_trials',          help='Number of trials ', type=int, default=2)\n",
    "    parser.add_argument('--top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--true_top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--context_dim',          help='Context dim for patients and providers', type=int, default=5)\n",
    "    parser.add_argument('--max_menu_size',          help='Context dim for patients and providers', type=int, default=50)\n",
    "    parser.add_argument('--num_repetitions',          help='Context dim for patients and providers', type=int, default=1)\n",
    "    parser.add_argument('--previous_patients_per_provider',          help='Context dim for patients and providers', type=int, default=10)\n",
    "    parser.add_argument('--provider_capacity', help='Provider Capacity', type=int, default=5)\n",
    "    parser.add_argument('--choice_model', help='Which choice model for patients', type=str, default='uniform_choice')\n",
    "    parser.add_argument('--exit_option', help='What is the value of the exit option', type=float, default=0.5)\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='policy_comparison')\n",
    "    parser.add_argument('--utility_function', help='Which folder to write results to', type=str, default='uniform')\n",
    "    parser.add_argument('--order', help='Which folder to write results to', type=str, default='random')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    seed = args.seed\n",
    "    num_patients = args.n_patients\n",
    "    num_providers = args.n_providers \n",
    "    provider_capacity = args.provider_capacity\n",
    "    top_choice_prob = args.top_choice_prob\n",
    "    choice_model = args.choice_model\n",
    "    exit_option = args.exit_option\n",
    "    out_folder = args.out_folder\n",
    "    num_trials = args.n_trials \n",
    "    context_dim = args.context_dim \n",
    "    num_repetitions = args.num_repetitions\n",
    "    true_top_choice_prob = args.true_top_choice_prob\n",
    "    max_menu_size = args.max_menu_size\n",
    "    utility_function = args.utility_function\n",
    "    order = args.order\n",
    "    previous_patients_per_provider = args.previous_patients_per_provider\n",
    "\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'num_patients'    : num_patients,\n",
    "        'num_providers': num_providers, \n",
    "        'provider_capacity'    : provider_capacity,\n",
    "        'top_choice_prob': top_choice_prob, \n",
    "        'choice_model': choice_model,\n",
    "        'exit_option': exit_option,\n",
    "        'num_trials': num_trials,\n",
    "        'context_dim': context_dim, \n",
    "        'true_top_choice_prob': true_top_choice_prob, \n",
    "        'num_repetitions': num_repetitions, \n",
    "        'max_menu_size': max_menu_size, \n",
    "        'utility_function': utility_function, \n",
    "        'order': order, \n",
    "        'previous_patients_per_provider': previous_patients_per_provider} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [seed]\n",
    "restrict_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random policy\n",
      "Available providers [[93. 90. 86. 99. 89.]\n",
      " [95. 79. 83. 99. 91.]\n",
      " [94. 85. 78. 98. 91.]\n",
      " [94. 89. 85. 98. 93.]\n",
      " [94. 85. 78. 98. 93.]]\n",
      "Selected [[ 1.  9. 13.  0.  3.]\n",
      " [ 3.  3. 11.  1.  3.]\n",
      " [ 3.  4.  1.  2.  4.]\n",
      " [ 5.  8.  9.  2.  2.]\n",
      " [ 4. 14.  4.  1.  9.]]\n",
      "Prob [16. 38. 38.  6. 21.]\n",
      "Took 0.01686239242553711 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.238, 0.17849495358034292)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = random_policy\n",
    "name = \"random\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_repetitions*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_repetitions*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy_basic policy\n",
      "Available providers [[ 99.  78.  79. 100.  99.]\n",
      " [ 98.  77.  73. 100.  97.]\n",
      " [100.  81.  63. 100.  97.]\n",
      " [100.  80.  78. 100. 100.]\n",
      " [100.  82.  65. 100.  99.]]\n",
      "Selected [[ 0.  4. 21.  0.  2.]\n",
      " [ 1.  3. 18.  0.  1.]\n",
      " [ 1. 12.  2.  0.  0.]\n",
      " [ 2.  6. 21.  0.  0.]\n",
      " [ 0. 28.  1.  0.  4.]]\n",
      "Prob [ 4. 53. 63.  0.  7.]\n",
      "Took 0.015822649002075195 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6374367699012243, 0.07273152217661365, 0.004956503958676469)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = all_ones_policy\n",
    "name = \"greedy_basic\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.mean(results['{}_minimums_all'.format(name)]),np.mean(results['{}_gaps_all'.format(name)]),np.mean(results['{}_variance_all'.format(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy policy\n",
      "Available providers [[ 84.  38.  38. 100.  89.]\n",
      " [ 86.  47.  37. 100.  84.]\n",
      " [ 93.  52.  31. 100.  82.]\n",
      " [ 95.  49.  43. 100.  85.]\n",
      " [ 76.  41.  24. 100.  84.]]\n",
      "Selected [[ 5. 10. 32.  4. 30.]\n",
      " [10. 13. 28.  3. 21.]\n",
      " [30. 38.  1.  5.  1.]\n",
      " [27. 12. 35.  2.  2.]\n",
      " [ 4. 26.  3.  7. 27.]]\n",
      "Prob [76. 99. 99. 21. 81.]\n",
      "Took 0.024454832077026367 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/patient_provider/patient/simulator.py:399: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  provider_workloads = [sum([len(j) for j in i])/len(i) for i in np.array(utilities_by_provider).T]\n",
      "/usr0/home/naveenr/projects/patient_provider/patient/simulator.py:403: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  scores['matches'].append(num_matches)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.752, 0.5493837768444477)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = greedy_policy\n",
    "name = \"greedy\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2**(num_patients*num_providers)*2**(num_patients)*math.factorial(num_patients) < 100000:\n",
    "    policy = one_shot_policy\n",
    "    per_epoch_function = optimal_policy\n",
    "    name = \"optimal\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_order policy\n",
      "Took 0.017654895782470703 time\n",
      "0.758 0.5405452364134852\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = optimal_order_policy\n",
    "name = \"optimal_order\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp policy\n",
      "Available providers [[ 54.  62.  62.  71. 100.]\n",
      " [ 58.  64. 100.  72.  60.]\n",
      " [ 58. 100.  63.  73.  64.]\n",
      " [100.  67.  63.  77.  65.]\n",
      " [ 49.  56.  63. 100.  57.]]\n",
      "Selected [[ 0.  0.  0.  0. 81.]\n",
      " [ 0.  0. 75.  0.  0.]\n",
      " [ 0. 75.  0.  0.  0.]\n",
      " [78.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 67.  0.]]\n",
      "Prob [78. 75. 75. 67. 81.]\n",
      "Took 0.019945621490478516 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.752, 0.5058918875744991, 6.507526357039188)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_policy\n",
    "name = \"lp\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_workload policy\n",
      "Took 0.5431537628173828 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 6.892960645691221, 6.892960645691221)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_workload_policy\n",
    "name = \"lp_workload\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_multiple_match policy\n",
      "Took 0.09562230110168457 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2536, 0.23916547111746667)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_multiple_match_policy\n",
    "name = \"lp_multiple_match\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice_model == 'threshold':\n",
    "    policy = one_shot_policy \n",
    "    per_epoch_function = lp_threshold\n",
    "    name = \"lp_threshold\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_more_patients policy\n",
      "Took 0.6590728759765625 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = lp_more_patients_policy\n",
    "name = \"lp_more_patients\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_fairness policy\n",
      "Took 0.5672309398651123 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.4479570155876951)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_fairness_policy\n",
    "name = \"lp_fairness\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based policy\n",
      "Took 0.715339183807373 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_policy\n",
    "name = \"group_based\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based_unidirectional policy\n",
      "Took 0.7381973266601562 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7504, 0.5187739882075151)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_unidirectional_policy\n",
    "name = \"group_based_unidirectional\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused policy\n",
      "B 3, Per provider [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3.], Per Patient [1. 4. 1. 3. 4. 4. 3. 4. 2. 5. 1. 1. 2. 5. 2. 2. 3. 2. 4. 4. 5. 5. 1. 4.\n",
      " 3.]\n",
      "Took 0.1559138298034668 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6824, 0.511133744634547)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_policy\n",
    "name = \"provider_focused\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_less_interference policy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seed_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_705884/2735123428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} policy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_multi_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper_epoch_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}_matches'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed_list' is not defined"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_less_interference_policy\n",
    "name = \"provider_focused_less_interference\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_linear_regularization_0.25 policy\n",
      "B 1, Per provider [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [2. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "Took 0.03953838348388672 time\n",
      "0.25 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_0.5 policy\n",
      "B 1, Per provider [1. 0. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [1. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/patient_provider/patient/provider_policies.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  real_value += upper/lower*prod\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0397343635559082 time\n",
      "0.5 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_1 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.031838178634643555 time\n",
      "1 0.0 0.0\n",
      "provider_focused_linear_regularization_2 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03140616416931152 time\n",
      "2 0.0 0.0\n",
      "provider_focused_linear_regularization_4 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03318023681640625 time\n",
      "4 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# policy = one_shot_policy \n",
    "# for lamb in [0.25,0.5,1,2,4]:\n",
    "#     per_epoch_function = provider_focused_linear_regularization_policy(lamb)\n",
    "#     name = \"provider_focused_linear_regularization_{}\".format(lamb)\n",
    "#     print(\"{} policy\".format(name))\n",
    "\n",
    "#     rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "#     results['{}_matches'.format(name)] = rewards['matches']\n",
    "#     results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "#     results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "#     results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "#     results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "#     results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "#     results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "#     results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "#     results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "#     results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "#     print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = one_shot_policy \n",
    "# for lamb in [0,0.1,0.25,0.5]:#,1,2,4]:\n",
    "#     per_epoch_function = provider_focused_log_regularization_policy(lamb)\n",
    "#     name = \"provider_focused_log_regularization_{}\".format(lamb)\n",
    "#     print(\"{} policy\".format(name))\n",
    "\n",
    "#     rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "#     results['{}_matches'.format(name)] = rewards['matches']\n",
    "#     results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "#     results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "#     results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "#     results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "#     results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "#     results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "#     results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "#     results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "#     results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "#     print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = one_shot_policy \n",
    "# per_epoch_function = gradient_descent_policy\n",
    "# name = \"gradient_descent\"\n",
    "# print(\"{} policy\".format(name))\n",
    "\n",
    "# rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "# results['{}_matches'.format(name)] = rewards['matches']\n",
    "# results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "# results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "# results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "# results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "# results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "# results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "# results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "# results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "# results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "# print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent_2 policy\n",
      "Available providers [[ 84.  38.  40. 100.  87.]\n",
      " [ 87.  47.  38. 100.  82.]\n",
      " [ 93.  52.  31. 100.  82.]\n",
      " [ 95.  49.  45. 100.  83.]\n",
      " [ 76.  41.  24. 100.  84.]]\n",
      "Selected [[ 5. 10. 33.  4. 29.]\n",
      " [11. 13. 29.  3. 19.]\n",
      " [30. 38.  1.  5.  1.]\n",
      " [26. 12. 36.  2.  2.]\n",
      " [ 4. 26.  0.  7. 30.]]\n",
      "Prob [76. 99. 99. 21. 81.]\n",
      "Took 0.020916223526000977 time\n",
      "0.752 0.5496695226211828\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = gradient_descent_policy_2\n",
    "name = \"gradient_descent_2\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective2(z, theta, p, sorted_theta,lamb=1, smooth_reg='entropy', epsilon=1e-5):\n",
    "    # Step 1: Compute sigmoid\n",
    "    x = torch.sigmoid(z)\n",
    "\n",
    "    # Step 2: Argsort `theta` and gather `x`\n",
    "    argsorted = torch.argsort(theta, dim=1, descending=True)\n",
    "    sorted_theta = theta.gather(1, argsorted)\n",
    "    sorted_x = x.gather(1, argsorted)\n",
    "\n",
    "    # Step 3: Compute rows_with_top_i\n",
    "    rows_with_top_i = torch.cumsum((sorted_x > 0).float(), dim=0).transpose(0, 1)\n",
    "    rows_with_top_i /= (theta.shape[0] - 1)\n",
    "\n",
    "    # Step 4: Compute `is_top_k`\n",
    "    is_top_k = torch.cumsum((sorted_x > 0).float() / (theta.shape[0] - 1), dim=1).transpose(0, 1)\n",
    "\n",
    "    # Step 5: Normalize `x`\n",
    "    S = theta.shape[0]\n",
    "    scaled_x = torch.zeros_like(sorted_x)\n",
    "    prod = torch.ones_like(sorted_x[:, :1])  # Start cumulative product with 1\n",
    "\n",
    "    for top_num in range(S):\n",
    "        delta = rows_with_top_i[:, top_num].unsqueeze(1) - is_top_k[:, :, top_num].transpose(0, 1)\n",
    "        if top_num < S - 1:\n",
    "            prod = prod * (1 - p * delta)\n",
    "        scaled_x[:, top_num] = (1 / S) * prod.squeeze()\n",
    "\n",
    "    # Scatter back scaled values to original order\n",
    "    normalized_x = torch.zeros_like(x)\n",
    "    normalized_x.scatter_(1, argsorted, scaled_x)\n",
    "\n",
    "    # Step 6: Compute cumulative products for scaling\n",
    "    one_minus_normalized_x = 1 - normalized_x\n",
    "    cumprods = torch.cumprod(one_minus_normalized_x, dim=1)\n",
    "    shifted_cumprods = torch.cat([torch.ones(cumprods.size(0), 1, device=cumprods.device), cumprods[:, :-1]], dim=1)\n",
    "    scaled_normalized_x = normalized_x * shifted_cumprods\n",
    "\n",
    "    # Final normalization\n",
    "    normalized_x = scaled_normalized_x / torch.sum(scaled_normalized_x, dim=1, keepdim=True)\n",
    "\n",
    "    # Step 7: Compute the loss\n",
    "    term = p * torch.sum(normalized_x * theta, dim=0)\n",
    "    term = torch.sum(term) / theta.shape[1]  # Normalize by the number of columns\n",
    "\n",
    "    # Step 8: Add smooth regularization\n",
    "    if smooth_reg == 'logit' and lamb > 0:\n",
    "        reg_term = torch.sum(torch.logit(x, eps=epsilon) ** 2)  # Logit-based penalty\n",
    "    elif smooth_reg == 'entropy' and lamb > 0:\n",
    "        reg_term = -torch.sum(x * torch.log(x + epsilon) + (1 - x) * torch.log(1 - x + epsilon))  # Entropy-based penalty\n",
    "    else:\n",
    "        reg_term = 0\n",
    "\n",
    "    # Final loss\n",
    "    loss = term - lamb * reg_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter:\n",
    "    theta = [p.provider_rewards for p in simulator.patients]\n",
    "    theta = torch.Tensor(theta)\n",
    "    sorted_theta = torch.argsort(theta, dim=1,descending=True)  # Sorting indices of `theta` row-wise\n",
    "    opt_tensor = torch.Tensor(lp_policy(simulator))\n",
    "    ones_tensor = torch.Tensor(np.ones(opt_tensor.shape))\n",
    "    x = torch.Tensor(gradient_descent_policy_2(simulator))\n",
    "    p = true_top_choice_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1288754/1694301329.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_jupyter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones_tensor\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorted_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorted_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_tensor\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorted_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1288754/2435184590.py\u001b[0m in \u001b[0;36mobjective2\u001b[0;34m(z, theta, p, sorted_theta, lamb, smooth_reg, epsilon)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtop_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows_with_top_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mis_top_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtop_num\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprod\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "if is_jupyter:\n",
    "    print(objective2(ones_tensor*10000-10000/2,theta,p,sorted_theta,0))\n",
    "    print(objective2(x*10000-10000/2,theta,p,sorted_theta,0))\n",
    "    print(objective2(opt_tensor*10000-10000/2,theta,p,sorted_theta,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../../results/'+save_path,'w'),cls=MyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
