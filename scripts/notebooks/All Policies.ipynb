{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import secrets\n",
    "import json\n",
    "import sys\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patient.simulator import run_multi_seed\n",
    "from patient.baseline_policies import *\n",
    "from patient.lp_policies import *\n",
    "from patient.group_based_policies import *\n",
    "from patient.ordering_policies import *\n",
    "from patient.provider_policies import *\n",
    "from patient.utils import get_save_path, delete_duplicate_results, restrict_resources, one_shot_policy, MyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 43\n",
    "    num_patients = 3\n",
    "    num_providers = 3\n",
    "    provider_capacity = 1\n",
    "    top_choice_prob = 0.5\n",
    "    true_top_choice_prob = 0.5\n",
    "    choice_model = \"uniform_choice\"\n",
    "    exit_option = 0.5\n",
    "    utility_function = \"normal\"\n",
    "    out_folder = \"policy_comparison\"\n",
    "    num_repetitions = 1\n",
    "    num_trials = 100\n",
    "    context_dim = 5\n",
    "    max_menu_size = 25\n",
    "    previous_patients_per_provider = 10\n",
    "    order=\"custom\"\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', help='Random Seed', type=int, default=42)\n",
    "    parser.add_argument('--n_patients',         '-N', help='Number of patients', type=int, default=100)\n",
    "    parser.add_argument('--n_providers',        help='Number of providers', type=int, default=100)\n",
    "    parser.add_argument('--n_trials',          help='Number of trials ', type=int, default=2)\n",
    "    parser.add_argument('--top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--true_top_choice_prob',          help='Probability of picking top choice', type=float, default=0.75)\n",
    "    parser.add_argument('--context_dim',          help='Context dim for patients and providers', type=int, default=5)\n",
    "    parser.add_argument('--max_menu_size',          help='Context dim for patients and providers', type=int, default=50)\n",
    "    parser.add_argument('--num_repetitions',          help='Context dim for patients and providers', type=int, default=1)\n",
    "    parser.add_argument('--previous_patients_per_provider',          help='Context dim for patients and providers', type=int, default=10)\n",
    "    parser.add_argument('--provider_capacity', help='Provider Capacity', type=int, default=5)\n",
    "    parser.add_argument('--choice_model', help='Which choice model for patients', type=str, default='uniform_choice')\n",
    "    parser.add_argument('--exit_option', help='What is the value of the exit option', type=float, default=0.5)\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='policy_comparison')\n",
    "    parser.add_argument('--utility_function', help='Which folder to write results to', type=str, default='uniform')\n",
    "    parser.add_argument('--order', help='Which folder to write results to', type=str, default='random')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    seed = args.seed\n",
    "    num_patients = args.n_patients\n",
    "    num_providers = args.n_providers \n",
    "    provider_capacity = args.provider_capacity\n",
    "    top_choice_prob = args.top_choice_prob\n",
    "    choice_model = args.choice_model\n",
    "    exit_option = args.exit_option\n",
    "    out_folder = args.out_folder\n",
    "    num_trials = args.n_trials \n",
    "    context_dim = args.context_dim \n",
    "    num_repetitions = args.num_repetitions\n",
    "    true_top_choice_prob = args.true_top_choice_prob\n",
    "    max_menu_size = args.max_menu_size\n",
    "    utility_function = args.utility_function\n",
    "    order = args.order\n",
    "    previous_patients_per_provider = args.previous_patients_per_provider\n",
    "\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'num_patients'    : num_patients,\n",
    "        'num_providers': num_providers, \n",
    "        'provider_capacity'    : provider_capacity,\n",
    "        'top_choice_prob': top_choice_prob, \n",
    "        'choice_model': choice_model,\n",
    "        'exit_option': exit_option,\n",
    "        'num_trials': num_trials,\n",
    "        'context_dim': context_dim, \n",
    "        'true_top_choice_prob': true_top_choice_prob, \n",
    "        'num_repetitions': num_repetitions, \n",
    "        'max_menu_size': max_menu_size, \n",
    "        'utility_function': utility_function, \n",
    "        'order': order, \n",
    "        'previous_patients_per_provider': previous_patients_per_provider} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [seed]\n",
    "restrict_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random policy\n",
      "Available providers [[[0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.25252525252525254, 0.31313131313131315, 0.31313131313131315], [0.18279569892473116, 0.25806451612903225, 0.23655913978494625]], [[0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.24324324324324328, 0.2882882882882883, 0.2972972972972973], [0.17647058823529413, 0.22549019607843138, 0.2352941176470588]], [[0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.24444444444444444, 0.3, 0.26666666666666666], [0.1714285714285714, 0.2857142857142857, 0.29523809523809524]]]\n",
      "Top [[0.6, 0.3, 0.1], [0.58, 0.12, 0.3], [0.55, 0.08, 0.37]]\n",
      "Selected [[0.23, 0.16, 0.11], [0.16, 0.05, 0.14], [0.2, 0.11, 0.15]]\n",
      "Prob [0.59 0.32 0.4 ]\n",
      "Took 0.013100862503051758 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.43666666666666665, 0.27935593523858754)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = random_policy\n",
    "name = \"random\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_repetitions*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_repetitions*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy_basic policy\n",
      "Available providers [[[0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.1717171717171717, 0.3333333333333333, 0.3333333333333333], [0.04301075268817204, 0.3333333333333333, 0.22580645161290322]], [[0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.12612612612612614, 0.3333333333333333, 0.3333333333333333], [0.049019607843137254, 0.24509803921568626, 0.30392156862745096]], [[0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.13333333333333333, 0.3333333333333333, 0.3333333333333333], [0.09523809523809523, 0.3142857142857143, 0.27619047619047615]]]\n",
      "Top [[0.32, 0.49, 0.19], [0.3, 0.22, 0.48], [0.23, 0.21, 0.56]]\n",
      "Selected [[0.32, 0.26, 0.0], [0.23, 0.0, 0.24], [0.37, 0.02, 0.18]]\n",
      "Prob [0.92 0.28 0.42]\n",
      "Took 0.012835502624511719 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5892781888371939, 0.10091429656400962, 0.006089905801898968)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = all_ones_policy\n",
    "name = \"greedy_basic\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.mean(results['{}_minimums_all'.format(name)]),np.mean(results['{}_gaps_all'.format(name)]),np.mean(results['{}_variance_all'.format(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy policy\n",
      "Available providers [[[0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.1717171717171717, 0.3333333333333333, 0.3333333333333333], [0.04301075268817204, 0.3333333333333333, 0.22580645161290322]], [[0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.12612612612612614, 0.3333333333333333, 0.3333333333333333], [0.049019607843137254, 0.24509803921568626, 0.30392156862745096]], [[0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.13333333333333333, 0.3333333333333333, 0.3333333333333333], [0.09523809523809523, 0.3142857142857143, 0.27619047619047615]]]\n",
      "Top [[0.32, 0.49, 0.19], [0.3, 0.22, 0.48], [0.23, 0.21, 0.56]]\n",
      "Selected [[0.32, 0.26, 0.0], [0.23, 0.0, 0.24], [0.37, 0.02, 0.18]]\n",
      "Prob [0.92 0.28 0.42]\n",
      "Took 0.012889385223388672 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.54, 0.366493278281453)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = greedy_policy\n",
    "name = \"greedy\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'])\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2**(num_patients*num_providers)*2**(num_patients)*math.factorial(num_patients) < 100000:\n",
    "    policy = one_shot_policy\n",
    "    per_epoch_function = optimal_policy\n",
    "    name = \"optimal\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_order policy\n",
      "Took 0.017654895782470703 time\n",
      "0.758 0.5405452364134852\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = optimal_order_policy\n",
    "name = \"optimal_order\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp policy\n",
      "Available providers [[[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.07777777777777777, 0.1, 0.08888888888888888, 0.1, 0.1, 0.1, 0.08888888888888888, 0.1], [0.09166666666666666, 0.08333333333333333, 0.09166666666666666, 0.1, 0.1, 0.08333333333333333, 0.08333333333333333, 0.1, 0.08333333333333333, 0.1], [0.07272727272727272, 0.1, 0.1, 0.08181818181818182, 0.08181818181818182, 0.08181818181818182, 0.09090909090909091, 0.1, 0.09090909090909091, 0.08181818181818182], [0.0375, 0.1, 0.0875, 0.075, 0.0875, 0.0625, 0.075, 0.1, 0.0875, 0.0625], [0.03333333333333333, 0.075, 0.075, 0.05833333333333333, 0.05, 0.06666666666666667, 0.09166666666666666, 0.1, 0.05, 0.06666666666666667], [0.05, 0.08, 0.09, 0.08, 0.06000000000000001, 0.05, 0.08, 0.1, 0.07, 0.06000000000000001], [0.05454545454545454, 0.08181818181818182, 0.08181818181818182, 0.06363636363636363, 0.045454545454545456, 0.05454545454545454, 0.06363636363636363, 0.1, 0.08181818181818182, 0.045454545454545456], [0.030000000000000006, 0.05, 0.07, 0.06000000000000001, 0.08, 0.09, 0.07, 0.1, 0.030000000000000006, 0.04], [0.025, 0.0625, 0.075, 0.0375, 0.0375, 0.075, 0.025, 0.1, 0.025, 0.0875]], [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.09, 0.09, 0.1, 0.1, 0.1, 0.1, 0.1, 0.06000000000000001, 0.1, 0.09], [0.09, 0.09, 0.09, 0.08, 0.09, 0.1, 0.1, 0.09, 0.1, 0.08], [0.06000000000000001, 0.09, 0.09, 0.09, 0.08, 0.1, 0.07, 0.08, 0.08, 0.08], [0.08, 0.08, 0.08666666666666667, 0.08, 0.08666666666666667, 0.1, 0.08666666666666667, 0.07333333333333333, 0.07333333333333333, 0.08], [0.06666666666666667, 0.08888888888888888, 0.06666666666666667, 0.08888888888888888, 0.06666666666666667, 0.1, 0.07777777777777777, 0.07777777777777777, 0.04444444444444444, 0.07777777777777777], [0.05333333333333333, 0.07333333333333333, 0.08666666666666667, 0.06666666666666667, 0.06, 0.1, 0.05333333333333333, 0.1, 0.04666666666666667, 0.08666666666666667], [0.05555555555555556, 0.06666666666666667, 0.04444444444444444, 0.08888888888888888, 0.04444444444444444, 0.1, 0.06666666666666667, 0.03333333333333333, 0.05555555555555556, 0.06666666666666667], [0.03333333333333333, 0.05555555555555556, 0.06666666666666667, 0.04444444444444444, 0.04444444444444444, 0.1, 0.04444444444444444, 0.03333333333333333, 0.06666666666666667, 0.04444444444444444], [0.016666666666666666, 0.08333333333333333, 0.06666666666666667, 0.03333333333333333, 0.06666666666666667, 0.1, 0.016666666666666666, 0.08333333333333333, 0.016666666666666666, 0.05]], [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.09230769230769231, 0.09230769230769231, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.08461538461538462, 0.08461538461538462], [0.08, 0.1, 0.1, 0.1, 0.08, 0.08, 0.1, 0.1, 0.08, 0.1], [0.08181818181818182, 0.07272727272727272, 0.08181818181818182, 0.1, 0.07272727272727272, 0.07272727272727272, 0.08181818181818182, 0.08181818181818182, 0.08181818181818182, 0.08181818181818182], [0.08888888888888888, 0.07777777777777777, 0.08888888888888888, 0.1, 0.08888888888888888, 0.05555555555555556, 0.07777777777777777, 0.05555555555555556, 0.1, 0.07777777777777777], [0.045454545454545456, 0.08181818181818182, 0.09090909090909091, 0.1, 0.045454545454545456, 0.05454545454545454, 0.07272727272727272, 0.05454545454545454, 0.07272727272727272, 0.08181818181818182], [0.05555555555555556, 0.07777777777777777, 0.1, 0.1, 0.05555555555555556, 0.05555555555555556, 0.06666666666666667, 0.04444444444444444, 0.04444444444444444, 0.07777777777777777], [0.05333333333333333, 0.06, 0.06, 0.1, 0.06666666666666667, 0.05333333333333333, 0.04666666666666667, 0.08, 0.06666666666666667, 0.05333333333333333], [0.02222222222222222, 0.05555555555555556, 0.07777777777777777, 0.1, 0.06666666666666667, 0.05555555555555556, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.04444444444444444], [0.030000000000000006, 0.07, 0.07, 0.1, 0.06000000000000001, 0.06000000000000001, 0.04, 0.06000000000000001, 0.05, 0.08]], [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.1, 0.1, 0.08333333333333333, 0.1, 0.1, 0.1, 0.08333333333333333], [0.07692307692307693, 0.08461538461538462, 0.1, 0.06923076923076923, 0.1, 0.08461538461538462, 0.09230769230769231, 0.08461538461538462, 0.08461538461538462, 0.08461538461538462], [0.075, 0.08333333333333333, 0.09166666666666666, 0.075, 0.1, 0.1, 0.09166666666666666, 0.06666666666666667, 0.075, 0.08333333333333333], [0.06666666666666667, 0.08333333333333333, 0.1, 0.08333333333333333, 0.1, 0.08333333333333333, 0.06666666666666667, 0.08333333333333333, 0.08333333333333333, 0.1], [0.06666666666666667, 0.09166666666666666, 0.075, 0.08333333333333333, 0.1, 0.041666666666666664, 0.06666666666666667, 0.06666666666666667, 0.075, 0.05833333333333333], [0.08, 0.08, 0.04, 0.06000000000000001, 0.1, 0.06000000000000001, 0.06000000000000001, 0.04, 0.04, 0.08], [0.05, 0.07, 0.07, 0.06000000000000001, 0.1, 0.030000000000000006, 0.07, 0.05, 0.05, 0.08], [0.0625, 0.075, 0.0625, 0.075, 0.1, 0.075, 0.0375, 0.1, 0.0375, 0.075], [0.03125, 0.0375, 0.06875, 0.0375, 0.1, 0.0625, 0.05625, 0.05, 0.05625, 0.05]], [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.1, 0.1, 0.09, 0.08, 0.1, 0.1, 0.1], [0.1, 0.09166666666666666, 0.1, 0.075, 0.1, 0.09166666666666666, 0.09166666666666666, 0.08333333333333333, 0.08333333333333333, 0.1], [0.1, 0.07777777777777777, 0.1, 0.06666666666666667, 0.07777777777777777, 0.08888888888888888, 0.08888888888888888, 0.08888888888888888, 0.06666666666666667, 0.06666666666666667], [0.04444444444444444, 0.1, 0.1, 0.06666666666666667, 0.08888888888888888, 0.06666666666666667, 0.08888888888888888, 0.07777777777777777, 0.04444444444444444, 0.07777777777777777], [0.045454545454545456, 0.08181818181818182, 0.1, 0.07272727272727272, 0.05454545454545454, 0.06363636363636363, 0.08181818181818182, 0.06363636363636363, 0.1, 0.07272727272727272], [0.05454545454545454, 0.07272727272727272, 0.1, 0.08181818181818182, 0.07272727272727272, 0.06363636363636363, 0.06363636363636363, 0.08181818181818182, 0.06363636363636363, 0.045454545454545456], [0.0125, 0.0625, 0.1, 0.0625, 0.05, 0.0625, 0.0875, 0.075, 0.075, 0.0625], [0.045454545454545456, 0.06363636363636363, 0.1, 0.045454545454545456, 0.05454545454545454, 0.05454545454545454, 0.01818181818181818, 0.05454545454545454, 0.045454545454545456, 0.06363636363636363], [0.041666666666666664, 0.041666666666666664, 0.1, 0.075, 0.041666666666666664, 0.05833333333333333, 0.05, 0.041666666666666664, 0.05, 0.05833333333333333]], [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.09285714285714285, 0.1, 0.09285714285714285, 0.08571428571428572, 0.09285714285714285, 0.08571428571428572, 0.1, 0.1, 0.1, 0.1], [0.08181818181818182, 0.1, 0.1, 0.1, 0.06363636363636363, 0.08181818181818182, 0.1, 0.08181818181818182, 0.1, 0.09090909090909091], [0.08181818181818182, 0.08181818181818182, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.08181818181818182, 0.08181818181818182, 0.09090909090909091, 0.1, 0.1], [0.08181818181818182, 0.08181818181818182, 0.08181818181818182, 0.05454545454545454, 0.07272727272727272, 0.07272727272727272, 0.09090909090909091, 0.08181818181818182, 0.1, 0.08181818181818182], [0.03333333333333333, 0.06666666666666667, 0.1, 0.06666666666666667, 0.08333333333333333, 0.08333333333333333, 0.05, 0.1, 0.1, 0.03333333333333333], [0.046153846153846156, 0.06923076923076923, 0.07692307692307693, 0.06923076923076923, 0.06153846153846154, 0.08461538461538462, 0.07692307692307693, 0.053846153846153856, 0.1, 0.038461538461538464], [0.06666666666666667, 0.05, 0.08333333333333333, 0.05, 0.08333333333333333, 0.08333333333333333, 0.03333333333333333, 0.06666666666666667, 0.1, 0.05], [0.05555555555555556, 0.04444444444444444, 0.07777777777777777, 0.06666666666666667, 0.06666666666666667, 0.03333333333333333, 0.03333333333333333, 0.03333333333333333, 0.1, 0.07777777777777777], [0.05, 0.05833333333333333, 0.05, 0.03333333333333333, 0.03333333333333333, 0.016666666666666666, 0.03333333333333333, 0.03333333333333333, 0.1, 0.041666666666666664]], [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.08, 0.08, 0.1, 0.1, 0.1, 0.1, 0.08], [0.08, 0.08, 0.09, 0.1, 0.09, 0.1, 0.1, 0.1, 0.09, 0.08], [0.1, 0.08333333333333333, 0.1, 0.08333333333333333, 0.06666666666666667, 0.08333333333333333, 0.1, 0.1, 0.06666666666666667, 0.06666666666666667], [0.07, 0.08, 0.1, 0.07, 0.07, 0.06000000000000001, 0.1, 0.08, 0.09, 0.06000000000000001], [0.08888888888888888, 0.06666666666666667, 0.08888888888888888, 0.07777777777777777, 0.07777777777777777, 0.08888888888888888, 0.1, 0.06666666666666667, 0.05555555555555556, 0.05555555555555556], [0.06000000000000001, 0.08, 0.05, 0.08, 0.06000000000000001, 0.05, 0.1, 0.030000000000000006, 0.07, 0.08], [0.05, 0.05833333333333333, 0.09166666666666666, 0.05833333333333333, 0.075, 0.05833333333333333, 0.1, 0.05833333333333333, 0.041666666666666664, 0.08333333333333333], [0.02, 0.08, 0.06666666666666667, 0.05333333333333333, 0.04666666666666667, 0.04, 0.1, 0.07333333333333333, 0.05333333333333333, 0.06666666666666667], [0.02, 0.04, 0.05, 0.06000000000000001, 0.07, 0.04, 0.1, 0.06000000000000001, 0.04, 0.030000000000000006]], [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.1, 0.09230769230769231, 0.1, 0.1, 0.08461538461538462, 0.1, 0.09230769230769231, 0.09230769230769231, 0.1, 0.1], [0.0875, 0.075, 0.0875, 0.1, 0.1, 0.0875, 0.1, 0.1, 0.075, 0.1], [0.05833333333333333, 0.1, 0.08333333333333333, 0.09166666666666666, 0.06666666666666667, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.1], [0.07272727272727272, 0.08181818181818182, 0.09090909090909091, 0.08181818181818182, 0.06363636363636363, 0.045454545454545456, 0.08181818181818182, 0.06363636363636363, 0.06363636363636363, 0.1], [0.06666666666666667, 0.1, 0.08888888888888888, 0.06666666666666667, 0.06666666666666667, 0.08888888888888888, 0.07777777777777777, 0.07777777777777777, 0.05555555555555556, 0.1], [0.08, 0.05, 0.09, 0.07, 0.07, 0.05, 0.05, 0.07, 0.09, 0.1], [0.05, 0.06666666666666667, 0.08333333333333333, 0.03333333333333333, 0.075, 0.041666666666666664, 0.05833333333333333, 0.05, 0.041666666666666664, 0.1], [0.03333333333333333, 0.06666666666666667, 0.06666666666666667, 0.03333333333333333, 0.03333333333333333, 0.03333333333333333, 0.06666666666666667, 0.03333333333333333, 0.06666666666666667, 0.1], [0.04444444444444444, 0.06666666666666667, 0.03333333333333333, 0.05555555555555556, 0.03333333333333333, 0.04444444444444444, 0.06666666666666667, 0.05555555555555556, 0.04444444444444444, 0.1]], [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.08181818181818182, 0.1, 0.1, 0.1, 0.1, 0.09090909090909091, 0.1, 0.09090909090909091, 0.1, 0.09090909090909091], [0.1, 0.1, 0.08888888888888888, 0.06666666666666667, 0.08888888888888888, 0.1, 0.07777777777777777, 0.1, 0.08888888888888888, 0.07777777777777777], [0.08571428571428572, 0.1, 0.1, 0.1, 0.1, 0.05714285714285714, 0.07142857142857142, 0.07142857142857142, 0.08571428571428572, 0.07142857142857142], [0.05714285714285714, 0.1, 0.07142857142857142, 0.1, 0.05714285714285714, 0.1, 0.08571428571428572, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.08571428571428572, 0.1, 0.08571428571428572, 0.04285714285714286, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.1], [0.03636363636363636, 0.1, 0.08181818181818182, 0.045454545454545456, 0.08181818181818182, 0.045454545454545456, 0.08181818181818182, 0.06363636363636363, 0.07272727272727272, 0.07272727272727272], [0.045454545454545456, 0.1, 0.09090909090909091, 0.06363636363636363, 0.03636363636363636, 0.045454545454545456, 0.07272727272727272, 0.05454545454545454, 0.05454545454545454, 0.06363636363636363], [0.06, 0.1, 0.06666666666666667, 0.04666666666666667, 0.04666666666666667, 0.04666666666666667, 0.05333333333333333, 0.06, 0.04, 0.06666666666666667], [0.05, 0.1, 0.06000000000000001, 0.07, 0.04, 0.07, 0.04, 0.05, 0.05, 0.04]], [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.08888888888888888, 0.1, 0.08888888888888888, 0.08888888888888888, 0.1, 0.1, 0.1], [0.1, 0.1, 0.08, 0.09, 0.09, 0.08, 0.1, 0.08, 0.09, 0.08], [0.1, 0.09090909090909091, 0.08181818181818182, 0.07272727272727272, 0.09090909090909091, 0.07272727272727272, 0.1, 0.07272727272727272, 0.08181818181818182, 0.08181818181818182], [0.1, 0.07857142857142857, 0.07857142857142857, 0.08571428571428572, 0.05714285714285714, 0.1, 0.07857142857142857, 0.09285714285714285, 0.05714285714285714, 0.07857142857142857], [0.1, 0.05714285714285714, 0.09285714285714285, 0.07857142857142857, 0.1, 0.05, 0.06428571428571428, 0.06428571428571428, 0.07857142857142857, 0.08571428571428572], [0.1, 0.08333333333333333, 0.1, 0.06666666666666667, 0.05, 0.06666666666666667, 0.06666666666666667, 0.08333333333333333, 0.03333333333333333, 0.06666666666666667], [0.1, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.05, 0.1, 0.03333333333333333, 0.06666666666666667, 0.03333333333333333, 0.05], [0.1, 0.045454545454545456, 0.06363636363636363, 0.06363636363636363, 0.06363636363636363, 0.045454545454545456, 0.06363636363636363, 0.02727272727272727, 0.06363636363636363, 0.05454545454545454], [0.1, 0.08571428571428572, 0.07142857142857142, 0.04285714285714286, 0.02857142857142857, 0.04285714285714286, 0.02857142857142857, 0.07142857142857142, 0.04285714285714286, 0.07142857142857142]]]\n",
      "Top [[0.01, 0.0, 0.23, 0.0, 0.0, 0.05, 0.0, 0.0, 0.71, 0.0], [0.0, 0.0, 0.09, 0.0, 0.0, 0.53, 0.0, 0.0, 0.38, 0.0], [0.64, 0.0, 0.08, 0.0, 0.0, 0.04, 0.0, 0.0, 0.24, 0.0], [0.02, 0.0, 0.82, 0.0, 0.0, 0.12, 0.0, 0.0, 0.04, 0.0], [0.07, 0.05, 0.6, 0.0, 0.0, 0.27, 0.0, 0.0, 0.01, 0.0], [0.7, 0.0, 0.12, 0.0, 0.0, 0.03, 0.01, 0.0, 0.14, 0.0], [0.02, 0.0, 0.82, 0.0, 0.0, 0.1, 0.0, 0.0, 0.06, 0.0], [0.17, 0.0, 0.03, 0.0, 0.0, 0.71, 0.0, 0.0, 0.09, 0.0], [0.69, 0.0, 0.25, 0.0, 0.0, 0.03, 0.0, 0.0, 0.03, 0.0], [0.35, 0.0, 0.15, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0]]\n",
      "Selected [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.47, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.48, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47], [0.0, 0.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.65, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "Prob [0.65 0.42 0.4  0.48 0.56 0.47 0.56 0.47 0.56 0.47]\n",
      "Took 0.04658961296081543 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.504, 0.35372341223777015, 6.774190075984558)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_policy\n",
    "name = \"lp\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_workload policy\n",
      "Took 0.5431537628173828 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 6.892960645691221, 6.892960645691221)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_workload_policy\n",
    "name = \"lp_workload\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0)),np.max(np.mean(np.array(rewards['final_workloads'])[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_multiple_match policy\n",
      "Took 0.09562230110168457 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2536, 0.23916547111746667)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_multiple_match_policy\n",
    "name = \"lp_multiple_match\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choice_model == 'threshold':\n",
    "    policy = one_shot_policy \n",
    "    per_epoch_function = lp_threshold\n",
    "    name = \"lp_threshold\"\n",
    "    print(\"{} policy\".format(name))\n",
    "\n",
    "    rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "    results['{}_matches'.format(name)] = rewards['matches']\n",
    "    results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "    results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "    results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "    results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "    results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "    results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "    results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "    results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "    results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "    print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_more_patients policy\n",
      "Took 0.6590728759765625 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = lp_more_patients_policy\n",
    "name = \"lp_more_patients\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_fairness policy\n",
      "Took 0.5672309398651123 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.4479570155876951)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = lp_fairness_policy\n",
    "name = \"lp_fairness\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based policy\n",
      "Took 0.715339183807373 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7636, 0.5261014333470473)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_policy\n",
    "name = \"group_based\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_based_unidirectional policy\n",
      "Took 0.7381973266601562 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7504, 0.5187739882075151)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy\n",
    "per_epoch_function = group_based_unidirectional_policy\n",
    "name = \"group_based_unidirectional\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused policy\n",
      "B 3, Per provider [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3.], Per Patient [1. 4. 1. 3. 4. 4. 3. 4. 2. 5. 1. 1. 2. 5. 2. 2. 3. 2. 4. 4. 5. 5. 1. 4.\n",
      " 3.]\n",
      "Took 0.1559138298034668 time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6824, 0.511133744634547)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_policy\n",
    "name = \"provider_focused\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_less_interference policy\n",
      "Took 0.012698888778686523 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/patient_provider/patient/simulator.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  scores['initial_workloads'].append(initial_workloads)\n",
      "/usr0/home/naveenr/projects/patient_provider/patient/simulator.py:415: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  scores['provider_workloads'].append(provider_workloads)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5233333333333333, 0.3530933209480684)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = provider_focused_less_interference_policy\n",
    "name = \"provider_focused_less_interference\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider_focused_linear_regularization_0.25 policy\n",
      "B 1, Per provider [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [2. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "Took 0.03953838348388672 time\n",
      "0.25 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_0.5 policy\n",
      "B 1, Per provider [1. 0. 1. 1. 1. 1. 1. 0. 1. 1.], Per Patient [1. 2. 1. 1. 1. 0. 1. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/patient_provider/patient/provider_policies.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  real_value += upper/lower*prod\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0397343635559082 time\n",
      "0.5 0.7 0.49648776357158675\n",
      "provider_focused_linear_regularization_1 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.031838178634643555 time\n",
      "1 0.0 0.0\n",
      "provider_focused_linear_regularization_2 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03140616416931152 time\n",
      "2 0.0 0.0\n",
      "provider_focused_linear_regularization_4 policy\n",
      "B 1, Per provider [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Per Patient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Took 0.03318023681640625 time\n",
      "4 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# policy = one_shot_policy \n",
    "# for lamb in [0.25,0.5,1,2,4]:\n",
    "#     per_epoch_function = provider_focused_linear_regularization_policy(lamb)\n",
    "#     name = \"provider_focused_linear_regularization_{}\".format(lamb)\n",
    "#     print(\"{} policy\".format(name))\n",
    "\n",
    "#     rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "#     results['{}_matches'.format(name)] = rewards['matches']\n",
    "#     results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "#     results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "#     results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "#     results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "#     results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "#     results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "#     results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "#     results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "#     results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "#     print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = one_shot_policy \n",
    "# for lamb in [0,0.1,0.25,0.5]:#,1,2,4]:\n",
    "#     per_epoch_function = provider_focused_log_regularization_policy(lamb)\n",
    "#     name = \"provider_focused_log_regularization_{}\".format(lamb)\n",
    "#     print(\"{} policy\".format(name))\n",
    "\n",
    "#     rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "#     results['{}_matches'.format(name)] = rewards['matches']\n",
    "#     results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "#     results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "#     results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "#     results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "#     results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "#     results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "#     results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "#     results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "#     results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "#     print(lamb,np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = one_shot_policy \n",
    "# per_epoch_function = gradient_descent_policy\n",
    "# name = \"gradient_descent\"\n",
    "# print(\"{} policy\".format(name))\n",
    "\n",
    "# rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "# results['{}_matches'.format(name)] = rewards['matches']\n",
    "# results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "# results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "# results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "# results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "# results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "# results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "# results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "# results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "# results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "# print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent_2 policy\n",
      "Before 0.01928091049194336\n",
      "Took 0.013289928436279297 time\n",
      "0.54 0.366493278281453\n"
     ]
    }
   ],
   "source": [
    "policy = one_shot_policy \n",
    "per_epoch_function = gradient_descent_policy_2\n",
    "name = \"gradient_descent_2\"\n",
    "print(\"{} policy\".format(name))\n",
    "\n",
    "rewards, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function)\n",
    "\n",
    "results['{}_matches'.format(name)] = rewards['matches']\n",
    "results['{}_utilities'.format(name)] = rewards['patient_utilities']\n",
    "results['{}_workloads'.format(name)] = rewards['provider_workloads']\n",
    "\n",
    "results['{}_minimums'.format(name)] = rewards['provider_minimums']\n",
    "results['{}_minimums_all'.format(name)] = rewards['provider_minimums_all']\n",
    "results['{}_gaps'.format(name)] = rewards['provider_gaps']\n",
    "results['{}_gaps_all'.format(name)] = rewards['provider_gaps_all']\n",
    "results['{}_variance'.format(name)] = rewards['provider_variance']\n",
    "results['{}_variance_all'.format(name)] = rewards['provider_variance_all']\n",
    "results['{}_workload_diff'.format(name)] = [max(rewards['final_workloads'][0][i])-max(rewards['initial_workloads'][0][i]) for i in range(len(rewards['final_workloads'][0]))]\n",
    "\n",
    "print(np.sum(rewards['matches'])/(num_patients*num_trials*len(seed_list)),np.sum(rewards['patient_utilities'])/(num_patients*num_trials*len(seed_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "def objective2(z, theta, p, sorted_theta,lamb=1, smooth_reg='entropy', epsilon=1e-5):\n",
    "    start = time.time()\n",
    "    x = torch.sigmoid(z)\n",
    "        \n",
    "    rows_with_top_i = torch.zeros((theta.shape[1], theta.shape[0]), device=theta.device)\n",
    "    argsorted = torch.argsort(theta, dim=1, descending=True)\n",
    "\n",
    "    # Mask elements in `argsorted` where x is 0\n",
    "    mask = x.gather(1, argsorted) != 0\n",
    "\n",
    "    # Filter out -1 indices\n",
    "    filtered_argsorted = [\n",
    "        torch.masked_select(argsorted[i], mask[i]) for i in range(len(argsorted))\n",
    "    ]\n",
    "    is_top_k = torch.zeros((theta.shape[0], theta.shape[1], theta.shape[0]), device=theta.device)\n",
    "    print(\"Checkpoint 0.5 {}\".format(time.time()-start))\n",
    "    # We need to update rows_with_top_i for each provider from their rank onwards\n",
    "    for patient in range(len(filtered_argsorted)):\n",
    "        # For each provider at the current rank\n",
    "        for rank in range(len(filtered_argsorted[patient])):\n",
    "            provider = filtered_argsorted[patient][rank]\n",
    "            # Update rows_with_top_i for this provider starting from the current rank onwards\n",
    "            rows_with_top_i[provider, rank:] += 1/(theta.shape[0] - 1)\n",
    "            is_top_k[patient,provider,rank:] +=  1 / (theta.shape[0] - 1)\n",
    "    print(\"Checkpoint 1 {}\".format(time.time()-start))\n",
    "\n",
    "    print(\"Checkpoint 1.1 {}\".format(time.time()-start))\n",
    "\n",
    "    # Step 4: Normalize `x`\n",
    "    delta = torch.sub(rows_with_top_i[None, :, :], is_top_k)\n",
    "    print(\"Checkpoint 1.25 {}\".format(time.time()-start))\n",
    "\n",
    "    delta = torch.cat((torch.zeros(delta.size(0), delta.size(1), 1, device=delta.device), delta[:, :, :-1]), dim=2)\n",
    "\n",
    "    print(\"Checkpoint 1.5 {}\".format(time.time()-start))\n",
    "\n",
    "    delta.mul_(p).neg_().add_(1)  # In-place: delta = 1 - p * delta\n",
    "    delta_raised = torch.cumprod(delta, dim=2)\n",
    "    # Raise delta to successive powers along the third dimension\n",
    "    delta_swapped = delta_raised.permute(0, 2, 1)\n",
    "\n",
    "    normalized_x = x[:,None,:] * delta_swapped\n",
    "    print(\"Checkpoint 2 {}\".format(time.time()-start))\n",
    "\n",
    "    # print(\"Normalized x {}\".format(normalized_x))\n",
    "\n",
    "    sorted_normalized_x = normalized_x.gather(dim=2, index=sorted_theta.unsqueeze(1).expand(-1, normalized_x.size(1), -1))\n",
    "\n",
    "    # Compute cumulative products (1 - normalized_x) along rows\n",
    "    one_minus_sorted = 1 - sorted_normalized_x\n",
    "    cumprods = torch.cumprod(one_minus_sorted, dim=2)\n",
    "\n",
    "    # # Shift the cumulative products to use for the original scaling (prepending 1 for first index)\n",
    "    shifted_cumprods = torch.cat([torch.ones(cumprods.size(0), cumprods.size(1) ,1,device=cumprods.device), cumprods[:,:,:-1]], dim=2)\n",
    "\n",
    "    print(\"Checkpoint 3 {}\".format(time.time()-start))\n",
    "\n",
    "    # Apply the cumulative product scaling to the original indices\n",
    "    scaled_normalized_x = sorted_normalized_x * shifted_cumprods\n",
    "    scaled_normalized_x = torch.mean(scaled_normalized_x,dim=1)\n",
    "\n",
    "    # Scatter back to the original positions\n",
    "    normalized_x = torch.zeros_like(scaled_normalized_x)\n",
    "    normalized_x.scatter_(1, sorted_theta, scaled_normalized_x)\n",
    "    # Normalize row-wise\n",
    "    # Compute numerator for the first term (using normalized x)\n",
    "    term = p * torch.sum(normalized_x * theta, dim=0)\n",
    "        \n",
    "    term = torch.sum(term) / theta.shape[1]  # Normalize by number of columns\n",
    "    print(\"Checkpoint 4 {}\".format(time.time()-start))\n",
    "\n",
    "    reg_term = 0\n",
    "    # Add smooth regularization term\n",
    "    if smooth_reg == 'logit' and lamb > 0:\n",
    "        reg_term = torch.sum(torch.logit(x, eps=epsilon) ** 2)  # Logit-based penalty\n",
    "    elif smooth_reg == 'entropy' and lamb > 0:\n",
    "        reg_term = -torch.sum(x * torch.log(x + epsilon) + (1 - x) * torch.log(1 - x + epsilon))  # Entropy-based penalty\n",
    "    loss = term - lamb * reg_term\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter:\n",
    "    theta = [p.provider_rewards for p in simulator.patients]\n",
    "    theta = torch.Tensor(theta)\n",
    "    sorted_theta = torch.argsort(theta, dim=1,descending=True)  # Sorting indices of `theta` row-wise\n",
    "    opt_tensor = torch.Tensor(lp_policy(simulator))\n",
    "    ones_tensor = torch.Tensor(np.ones(opt_tensor.shape))\n",
    "    # x = torch.Tensor(gradient_descent_policy_2(simulator))\n",
    "    p = true_top_choice_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0.5 0.00014162063598632812\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1386177/4187190426.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_jupyter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones_tensor\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorted_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# print(objective2(x*10000-10000/2,theta,p,sorted_theta,0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_tensor\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorted_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1386177/1267459735.py\u001b[0m in \u001b[0;36mobjective2\u001b[0;34m(z, theta, p, sorted_theta, lamb, smooth_reg, epsilon)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Broadcasting approach for rows_with_top_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mrows_with_top_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiltered_argsorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_providers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_patients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Broadcasting approach for is_top_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "if is_jupyter:\n",
    "    print(objective2(ones_tensor*10000-10000/2,theta,p,sorted_theta,0))\n",
    "    # print(objective2(x*10000-10000/2,theta,p,sorted_theta,0))\n",
    "    print(objective2(opt_tensor*10000-10000/2,theta,p,sorted_theta,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../../results/'+save_path,'w'),cls=MyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
